"""
LLM Assistant UI - Append to frontend_streamlit/app.py
"""


def render_llm_assistant():
    """LLMã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒšãƒ¼ã‚¸"""
    st.header("ğŸ¤– LLM Assistant")
    st.markdown("*è»½é‡LLMã«ã‚ˆã‚‹å¯¾è©±å‹è§£æã‚¢ãƒ‰ãƒã‚¤ã‚¹*")

    # LLMåˆ©ç”¨å¯èƒ½æ€§ç¢ºèª
    st.info(
        "ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: ãƒ•ãƒ«LLMæ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ `pip install gpt4all` ãŒå¿…è¦ã§ã™ã€‚"
        "æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®å ´åˆã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãŒè¿”ã•ã‚Œã¾ã™ã€‚"
    )

    # ã‚µãƒ–ã‚¿ãƒ–
    assistant_tabs = st.tabs([
        "ğŸ“Š ç‰¹å¾´é‡é¸æŠã‚¢ãƒ‰ãƒã‚¤ã‚¹",
        "ğŸ“‹ è§£æãƒ—ãƒ©ãƒ³ææ¡ˆ",
        "ğŸ¯ çµæœè§£é‡ˆ",
        "â“ è‡ªç”±Q&A"
    ])

    with assistant_tabs[0]:
        _render_feature_suggestion()

    with assistant_tabs[1]:
        _render_analysis_plan()

    with assistant_tabs[2]:
        _render_result_interpretation()

    with assistant_tabs[3]:
        _render_free_qa()


def _render_feature_suggestion():
    """ç‰¹å¾´é‡é¸æŠã‚¢ãƒ‰ãƒã‚¤ã‚¹"""
    st.subheader("ğŸ“Š ç‰¹å¾´é‡é¸æŠã‚¢ãƒ‰ãƒã‚¤ã‚¹")
    st.markdown("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‹ã‚‰ã€æœ€é©ãªç‰¹å¾´é‡ã‚»ãƒƒãƒˆã‚’æ¨å¥¨ã—ã¾ã™ã€‚")

    with st.form("feature_suggest_form"):
        col1, col2 = st.columns(2)

        with col1:
            n_samples = st.number_input(
                "ã‚µãƒ³ãƒ—ãƒ«æ•°", min_value=10, max_value=100000, value=500, step=10
            )
            task_type = st.selectbox("ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—", ["regression", "classification"])

        with col2:
            target_property = st.text_input(
                "äºˆæ¸¬å¯¾è±¡ã®ç‰©æ€§", value="solubility (logS)", placeholder="e.g., LogP, Tg"
            )

        submitted = st.form_submit_button("ğŸ¤” ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å–å¾—", use_container_width=True)

        if submitted:
            with st.spinner("LLMãŒè€ƒãˆä¸­..."):
                try:
                    res = requests.post(
                        f"{API_URL}/llm/suggest-features",
                        json={
                            "n_samples": n_samples,
                            "task_type": task_type,
                            "target_property": target_property,
                        },
                        timeout=60,
                    )

                    if res.status_code == 200:
                        result = res.json()

                        st.success("âœ… ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å–å¾—ã—ã¾ã—ãŸ")

                        # æ¨å¥¨ç‰¹å¾´é‡
                        st.markdown("### ğŸ¯ æ¨å¥¨ç‰¹å¾´é‡")
                        for feat in result["recommended_features"]:
                            st.markdown(f"- **{feat}**")

                        # ç†ç”±
                        st.markdown("### ğŸ’¡ ç†ç”±")
                        st.write(result["reasoning"])

                        # ä»£æ›¿æ¡ˆ
                        if result["alternative_features"]:
                            st.markdown("### ğŸ”„ ä»£æ›¿ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
                            for feat in result["alternative_features"]:
                                st.markdown(f"- {feat}")

                        # è€ƒæ…®äº‹é …
                        with st.expander("ğŸ“ è€ƒæ…®äº‹é …"):
                            for consideration in result["considerations"]:
                                st.write(f"â€¢ {consideration}")

                    else:
                        st.error(f"ã‚¨ãƒ©ãƒ¼: {res.status_code} - {res.text}")

                except Exception as e:
                    st.error(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


def _render_analysis_plan():
    """è§£æãƒ—ãƒ©ãƒ³ææ¡ˆ"""
    st.subheader("ğŸ“‹ è§£æãƒ—ãƒ©ãƒ³ææ¡ˆ")
    st.markdown("å•é¡Œè¨˜è¿°ã‹ã‚‰ã€è§£ææˆ¦ç•¥ã‚’ææ¡ˆã—ã¾ã™ã€‚")

    with st.form("analysis_plan_form"):
        problem_description = st.text_area(
            "å•é¡Œã®èª¬æ˜",
            value="Predict aqueous solubility from SMILES",
            height=100,
            placeholder="What are you trying to predict?",
        )

        col1, col2, col3 = st.columns(3)

        with col1:
            n_samples = st.number_input("ã‚µãƒ³ãƒ—ãƒ«æ•°", min_value=10, value=1200, step=10)

        with col2:
            task_type = st.selectbox("ã‚¿ã‚¹ã‚¯", ["regression", "classification"])

        with col3:
            target_property = st.text_input("ç‰©æ€§", value="logS")

        submitted = st.form_submit_button("ğŸ’¡ ãƒ—ãƒ©ãƒ³ã‚’ææ¡ˆ", use_container_width=True)

        if submitted:
            with st.spinner("è§£æãƒ—ãƒ©ãƒ³ã‚’ä½œæˆä¸­..."):
                try:
                    res = requests.post(
                        f"{API_URL}/llm/suggest-plan",
                        json={
                            "problem_description": problem_description,
                            "n_samples": n_samples,
                            "task_type": task_type,
                            "target_property": target_property,
                        },
                        timeout=60,
                    )

                    if res.status_code == 200:
                        result = res.json()

                        st.success("âœ… è§£æãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã—ã¾ã—ãŸ")

                        # ç›®çš„
                        st.markdown("### ğŸ¯ ç›®çš„")
                        st.write(result["objective"])

                        # æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
                        st.markdown("### ğŸ§­ æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ")
                        st.write(result["recommended_approach"])

                        # ãƒ¢ãƒ‡ãƒ«å€™è£œ
                        st.markdown("### ğŸ¤– æ¨å¥¨ãƒ¢ãƒ‡ãƒ«")
                        model_cols = st.columns(len(result["model_suggestions"]))
                        for i, model in enumerate(result["model_suggestions"]):
                            model_cols[i].info(model)

                        # æ¤œè¨¼æˆ¦ç•¥
                        st.markdown("### âœ… æ¤œè¨¼æˆ¦ç•¥")
                        st.write(result["validation_strategy"])

                        # èª²é¡Œ
                        with st.expander("âš ï¸ æƒ³å®šã•ã‚Œã‚‹èª²é¡Œ"):
                            for challenge in result["potential_challenges"]:
                                st.write(f"â€¢ {challenge}")

                    else:
                        st.error(f"ã‚¨ãƒ©ãƒ¼: {res.status_code} - {res.text}")

                except Exception as e:
                    st.error(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


def _render_result_interpretation():
    """çµæœè§£é‡ˆ"""
    st.subheader("ğŸ¯ ãƒ¢ãƒ‡ãƒ«çµæœã®è§£é‡ˆ")
    st.markdown("è©•ä¾¡æŒ‡æ¨™ã‹ã‚‰ã€çµæœã®è§£é‡ˆã¨æ”¹å–„æ¡ˆã‚’ææ¡ˆã—ã¾ã™ã€‚")

    with st.form("interpret_form"):
        st.markdown("#### è©•ä¾¡æŒ‡æ¨™ã‚’å…¥åŠ›")

        col1, col2 = st.columns(2)

        with col1:
            r2 = st.number_input("RÂ² Score", min_value=-1.0, max_value=1.0, value=0.85, step=0.01)
            mae = st.number_input("MAE", min_value=0.0, value=0.42, step=0.01)

        with col2:
            rmse = st.number_input("RMSE", min_value=0.0, value=0.58, step=0.01)
            model_type = st.text_input("ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—", value="XGBoost")

        submitted = st.form_submit_button("ğŸ” çµæœã‚’è§£é‡ˆ", use_container_width=True)

        if submitted:
            with st.spinner("è§£é‡ˆä¸­..."):
                try:
                    res = requests.post(
                        f"{API_URL}/llm/interpret-results",
                        json={
                            "metrics": {"r2": r2, "mae": mae, "rmse": rmse},
                            "model_type": model_type,
                        },
                        timeout=60,
                    )

                    if res.status_code == 200:
                        result = res.json()

                        st.success("âœ… è§£é‡ˆãŒå®Œäº†ã—ã¾ã—ãŸ")

                        # è§£é‡ˆ
                        st.markdown("### ğŸ’­ è§£é‡ˆ")
                        st.write(result["interpretation"])

                        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒãƒªãƒ¼
                        with st.expander("ğŸ“Š å…¥åŠ›ã•ã‚ŒãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹"):
                            metric_cols = st.columns(3)
                            metric_cols[0].metric("RÂ²", f"{r2:.3f}")
                            metric_cols[1].metric("MAE", f"{mae:.3f}")
                            metric_cols[2].metric("RMSE", f"{rmse:.3f}")

                    else:
                        st.error(f"ã‚¨ãƒ©ãƒ¼: {res.status_code} - {res.text}")

                except Exception as e:
                    st.error(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


def _render_free_qa():
    """è‡ªç”±å½¢å¼Q&A"""
    st.subheader("â“ è‡ªç”±Q&A")
    st.markdown("åŒ–å­¦æ©Ÿæ¢°å­¦ç¿’ã«é–¢ã™ã‚‹è³ªå•ã«å›ç­”ã—ã¾ã™ã€‚")

    # ã‚µãƒ³ãƒ—ãƒ«è³ªå•
    sample_questions = [
        "Morgan fingerprintsã¯ã„ã¤ä½¿ã†ã¹ãã§ã™ã‹ï¼Ÿ",
        "å°ã•ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ<100ã‚µãƒ³ãƒ—ãƒ«ï¼‰ã§éå­¦ç¿’ã‚’é¿ã‘ã‚‹ã«ã¯ï¼Ÿ",
        "XGBoostã¨LightGBMã®é•ã„ã¯ï¼Ÿ",
        "SHAPå€¤ã®è§£é‡ˆæ–¹æ³•ã¯ï¼Ÿ",
    ]

    selected_sample = st.selectbox(
        "ã‚µãƒ³ãƒ—ãƒ«è³ªå•ï¼ˆã¾ãŸã¯ä¸‹ã«è‡ªç”±å…¥åŠ›ï¼‰",
        ["-- è‡ªç”±å…¥åŠ› --"] + sample_questions
    )

    if selected_sample != "-- è‡ªç”±å…¥åŠ› --":
        question = selected_sample
    else:
        question = st.text_area(
            "è³ªå•ã‚’å…¥åŠ›",
            height=100,
            placeholder="ä¾‹: ãƒãƒƒãƒæ­£è¦åŒ–ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        )

    context = st.text_input("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰", placeholder="e.g., I'm working on QSAR modeling")

    if st.button("ğŸ¤” è³ªå•ã™ã‚‹", use_container_width=True):
        if not question:
            st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return

        with st.spinner("è€ƒãˆä¸­..."):
            try:
                payload = {"question": question}
                if context:
                    payload["context"] = context

                res = requests.post(
                    f"{API_URL}/llm/ask",
                    json=payload,
                    timeout=60,
                )

                if res.status_code == 200:
                    result = res.json()

                    st.success("âœ… å›ç­”ãŒå®Œäº†ã—ã¾ã—ãŸ")

                    # è³ªå•
                    st.markdown("### â“ è³ªå•")
                    st.info(result["question"])

                    # å›ç­”
                    st.markdown("### ğŸ’¡ å›ç­”")
                    st.write(result["answer"])

                    # LLMåˆ©ç”¨çŠ¶æ³
                    if result.get("llm_available"):
                        st.caption("âœ¨ GPT4All (Full LLM) ã‚’ä½¿ç”¨")
                    else:
                        st.caption("ğŸ“‹ ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ¼ãƒ‰ï¼ˆç°¡æ˜“å›ç­”ï¼‰")

                else:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {res.status_code} - {res.text}")

            except Exception as e:
                st.error(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
