"""
Chemical ML Platform - Streamlit Frontend

Implements: F-UI-001
è¨­è¨ˆæ€æƒ³:
- åˆå¿ƒè€…ã«ã¯ã‚·ãƒ³ãƒ—ãƒ«ã€ç†Ÿç·´è€…ã«ã¯è©³ç´°è¨­å®š
- ãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–é–‹ç¤ºUI
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–
"""

import streamlit as st
import requests
import pandas as pd
import numpy as np
import time
import base64
from typing import Optional, Dict, Any

# TARTEåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆé…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
def _check_tarte_available() -> bool:
    try:
        from core.services.features.tarte_eng import is_tarte_available
        return is_tarte_available()
    except ImportError:
        return False

try:
    from comparison import render_comparison
except ImportError:
    try:
        from frontend_streamlit.comparison import render_comparison
    except ImportError:
        def render_comparison():
            st.warning("Comparison module not found")


# APIè¨­å®š
API_URL = "http://127.0.0.1:8000/api"

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ChemML Platform",
    page_icon="ğŸ§ª",
    layout="wide",
    initial_sidebar_state="expanded",
)


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    st.title("ğŸ§ª Chemical ML Platform")
    st.markdown("*æ©Ÿæ¢°å­¦ç¿’ã‚’ä½¿ã£ãŸåˆ†å­ç‰©æ€§äºˆæ¸¬ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ *")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ Settings")
        show_advanced = st.checkbox("è©³ç´°è¨­å®šã‚’è¡¨ç¤º", value=False)
        auto_refresh = st.checkbox("è‡ªå‹•æ›´æ–° (10ç§’)", value=False)
        
        # TARTEè¨­å®š
        with st.expander("ğŸ¤– TARTE Settings", expanded=False):
            tarte_available = _check_tarte_available()
            if tarte_available:
                st.success("âœ… tarte-ai ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿")
                use_tarte = st.checkbox("TARTEã‚’ä½¿ç”¨", value=False, key="use_tarte_global")
                if use_tarte:
                    tarte_mode = st.radio(
                        "ãƒ¢ãƒ¼ãƒ‰é¸æŠ",
                        ["Featurizerï¼ˆé«˜é€Ÿï¼‰", "Finetuningï¼ˆé«˜ç²¾åº¦ï¼‰", "Boostingï¼ˆæœ€é«˜ç²¾åº¦ï¼‰"],
                        help="""
                        **Featurizer**: äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§åŸ‹ã‚è¾¼ã¿ç”Ÿæˆï¼ˆæ¨å¥¨ï¼‰
                        **Finetuning**: ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦ãƒ¢ãƒ‡ãƒ«èª¿æ•´
                        **Boosting**: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ï¼ˆæœ€ã‚‚æ™‚é–“ãŒã‹ã‹ã‚‹ï¼‰
                        """,
                        key="tarte_mode_global"
                    )
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                    mode_map = {
                        "Featurizerï¼ˆé«˜é€Ÿï¼‰": "featurizer",
                        "Finetuningï¼ˆé«˜ç²¾åº¦ï¼‰": "finetuning",
                        "Boostingï¼ˆæœ€é«˜ç²¾åº¦ï¼‰": "boosting",
                    }
                    st.session_state["tarte_mode"] = mode_map.get(tarte_mode, "featurizer")
            else:
                st.warning("âš ï¸ tarte-aiãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                st.markdown("è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã®Transformerç‰¹å¾´é‡ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™:")
                st.code("pip install tarte-ai", language="bash")
                st.caption("[ğŸ“š TARTE Documentation](https://github.com/soda-inria/tarte-ai)")
        
        st.divider()
        st.caption("Version 2.2 - TARTE Enhanced")
    
    # ãƒ¡ã‚¤ãƒ³ã‚¿ãƒ–
    tabs = st.tabs([
        "ğŸ“‚ Datasets",
        "âš—ï¸ Experiments",
        "ğŸ“Š Analysis",
        "ğŸ”¬ Molecule Viewer",
        "ğŸ“¦ Batch Predict",
        "âš–ï¸ Comparison",
        "ğŸ¤– LLM Assistant",  # NEW
    ])

    with tabs[0]:
        render_datasets()
    with tabs[1]:
        render_experiments(show_advanced)
    with tabs[2]:
        render_analysis()
    with tabs[3]:
        render_molecule_viewer()
    with tabs[4]:
        render_batch_predict()
    with tabs[5]:
        render_comparison()
    with tabs[6]:  # NEW
        render_llm_assistant()

    # è‡ªå‹•æ›´æ–°
    if auto_refresh:
        time.sleep(10)
        st.rerun()



def render_datasets():
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†ãƒšãƒ¼ã‚¸"""
    st.header("ğŸ“‚ Dataset Management")
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒ 
    with st.expander("ğŸ“¤ Upload New Dataset", expanded=False):
        with st.form("upload_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                name = st.text_input("Dataset Name", placeholder="e.g., Solubility Dataset")
                uploaded_file = st.file_uploader("Upload CSV", type=['csv'])
            
            with col2:
                smiles_col = st.text_input("SMILES Column", value="SMILES")
                target_col = st.text_input("Target Column", value="target")
            
            submitted = st.form_submit_button("Upload", use_container_width=True)
            
            if submitted and uploaded_file:
                _upload_dataset(name, uploaded_file, smiles_col, target_col)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§
    st.subheader("ğŸ“‹ Available Datasets")
    _display_datasets()


def _upload_dataset(name: str, file, smiles_col: str, target_col: str):
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    files = {'file': (file.name, file, 'text/csv')}
    data = {
        'name': name or file.name,
        'smiles_col': smiles_col,
        'target_col': target_col,
    }
    
    try:
        with st.spinner("Uploading..."):
            res = requests.post(f"{API_URL}/datasets", files=files, data=data, timeout=30)
        
        if res.status_code == 200:
            st.success(f"âœ… Dataset '{name}' uploaded successfully!")
            st.rerun()
        else:
            st.error(f"Error: {res.text}")
    except requests.exceptions.ConnectionError:
        st.error("âš ï¸ Cannot connect to API server")
    except Exception as e:
        st.error(f"Error: {e}")


def _display_datasets():
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§ã‚’è¡¨ç¤º"""
    try:
        res = requests.get(f"{API_URL}/datasets", timeout=10)
        
        if res.status_code == 200:
            datasets = res.json()
            if datasets:
                df = pd.DataFrame(datasets)
                st.dataframe(df, use_container_width=True)
            else:
                st.info("No datasets found. Upload one to get started!")
        else:
            st.error("Failed to fetch datasets")
    except requests.exceptions.ConnectionError:
        st.warning("âš ï¸ API server not available")
    except Exception as e:
        st.warning(f"Could not load datasets: {e}")


def render_experiments(show_advanced: bool = False):
    """å®Ÿé¨“ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒšãƒ¼ã‚¸"""
    st.header("âš—ï¸ Experiment Setup")
    
    # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—é¸æŠ
    st.subheader("ğŸ“‹ ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—")
    task_type = st.radio(
        "äºˆæ¸¬ã‚¿ã‚¹ã‚¯ã‚’é¸æŠ",
        [
            "â‘  SMILES â†’ ç‰©æ€§äºˆæ¸¬",
            "â‘¡ è¡¨ãƒ‡ãƒ¼ã‚¿ â†’ ç‰¹æ€§äºˆæ¸¬", 
            "â‘¢ æ··åˆç‰©ï¼ˆSMILESï¼‹å‰²åˆï¼‰ â†’ ç‰©æ€§äºˆæ¸¬",
            "â‘£ SMILESï¼‹è¡¨ãƒ‡ãƒ¼ã‚¿ â†’ ç‰©æ€§äºˆæ¸¬",
        ],
        horizontal=True,
        help="ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã«å¿œã˜ã¦é¸æŠã—ã¦ãã ã•ã„"
    )
    
    # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã‚’configç”¨ã«å¤‰æ›
    task_type_map = {
        "â‘  SMILES â†’ ç‰©æ€§äºˆæ¸¬": "smiles_only",
        "â‘¡ è¡¨ãƒ‡ãƒ¼ã‚¿ â†’ ç‰¹æ€§äºˆæ¸¬": "tabular_only",
        "â‘¢ æ··åˆç‰©ï¼ˆSMILESï¼‹å‰²åˆï¼‰ â†’ ç‰©æ€§äºˆæ¸¬": "mixture",
        "â‘£ SMILESï¼‹è¡¨ãƒ‡ãƒ¼ã‚¿ â†’ ç‰©æ€§äºˆæ¸¬": "smiles_tabular",
    }
    selected_task_type = task_type_map.get(task_type, "smiles_only")
    
    st.divider()
    
    # å®Ÿé¨“ä½œæˆãƒ•ã‚©ãƒ¼ãƒ 
    with st.form("exp_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            exp_name = st.text_input("Experiment Name", placeholder="e.g., LogP Prediction v1")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ
            dataset_options = _fetch_dataset_options()
            selected_ds_label = st.selectbox(
                "Select Dataset",
                list(dataset_options.keys()) if dataset_options else ["No datasets available"]
            )
        
        with col2:
            model_type = st.selectbox(
                "Model Type",
                ["lightgbm", "xgboost", "random_forest"],
                help="LightGBM is recommended for most cases"
            )
            
            # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸç‰¹å¾´é‡é¸æŠ
            if selected_task_type == "tabular_only":
                features = ["tabular"]
                st.info("ğŸ“Š è¡¨ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ¼ãƒ‰ï¼šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ•°å€¤ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨")
            elif selected_task_type == "mixture":
                features = ["mixture"]
                st.info("ğŸ§ª æ··åˆç‰©ãƒ¢ãƒ¼ãƒ‰ï¼šSMILES + å‰²åˆã‹ã‚‰åŠ é‡å¹³å‡è¨˜è¿°å­ã‚’è¨ˆç®—")
            else:
                # SMILESç³»ã‚¿ã‚¹ã‚¯: é€šå¸¸ã®ç‰¹å¾´é‡é¸æŠ + TARTEå¯¾å¿œ
                available_features = ["rdkit", "xtb", "uma"]
                feature_help = "rdkit: Molecular descriptors, xtb: Quantum properties, uma: UMAP embeddings"
                
                # TARTEãŒæœ‰åŠ¹ãªå ´åˆã¯è¿½åŠ ï¼ˆè¡¨ãƒ‡ãƒ¼ã‚¿æ··åˆã‚¿ã‚¹ã‚¯å‘ã‘ï¼‰
                if st.session_state.get("use_tarte_global", False):
                    if selected_task_type == "smiles_tabular":
                        available_features.append("tarte")
                        feature_help += ", tarte: Transformer tabular features"
                
                features = st.multiselect(
                    "Features",
                    available_features,
                    default=["rdkit"],
                    help=feature_help
                )
        
        # ç‰©æ€§ãƒ—ãƒªã‚»ãƒƒãƒˆé¸æŠï¼ˆSmart Feature Engineeringï¼‰
        st.divider()
        st.subheader("ğŸ¯ ç›®çš„ç‰©æ€§ï¼ˆSmart Feature Selectionï¼‰")
        
        # ç‰©æ€§ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ãƒ—ãƒªã‚»ãƒƒãƒˆ
        property_options = {
            "-- æ±ç”¨ --": {
                "general": "æ±ç”¨ï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰",
            },
            "-- å…‰å­¦ç‰©æ€§ --": {
                "refractive_index": "å±ˆæŠ˜ç‡",
                "optical_gap": "å…‰å­¦ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—",
            },
            "-- æ©Ÿæ¢°ç‰©æ€§ --": {
                "elastic_modulus": "å¼¾æ€§ç‡ãƒ»ãƒ¤ãƒ³ã‚°ç‡",
                "tensile_strength": "å¼•å¼µå¼·åº¦",
                "hardness": "ç¡¬åº¦",
            },
            "-- ç†±ç‰©æ€§ --": {
                "glass_transition": "ã‚¬ãƒ©ã‚¹è»¢ç§»æ¸©åº¦(Tg)",
                "melting_point": "èç‚¹",
                "thermal_conductivity": "ç†±ä¼å°ç‡",
                "thermal_stability": "ç†±å®‰å®šæ€§",
            },
            "-- é›»æ°—ç‰©æ€§ --": {
                "dielectric_constant": "èª˜é›»ç‡",
                "conductivity": "é›»æ°—ä¼å°åº¦",
            },
            "-- åŒ–å­¦ç‰©æ€§ --": {
                "solubility": "æº¶è§£åº¦ãƒ»LogP",
                "viscosity": "ç²˜åº¦",
                "density": "å¯†åº¦",
            },
            "-- è¼¸é€ç‰©æ€§ --": {
                "gas_permeability": "ã‚¬ã‚¹é€éæ€§",
            },
            "-- è–¬ç†å­¦ --": {
                "admet": "ADMETãƒ»è–¬ç‰©å‹•æ…‹",
                "pka": "pKa",
            },
        }
        
        # ãƒ•ãƒ©ãƒƒãƒˆãªãƒªã‚¹ãƒˆã«å¤‰æ›ï¼ˆè¡¨ç¤ºç”¨ï¼‰
        flat_options = []
        option_to_key = {}
        for category, presets in property_options.items():
            flat_options.append(category)
            for key, name in presets.items():
                display = f"  {name}"
                flat_options.append(display)
                option_to_key[display] = key
        
        selected_property_display = st.selectbox(
            "ç›®çš„ç‰©æ€§ã‚’é¸æŠï¼ˆæœ€é©ãªè¨˜è¿°å­ã‚»ãƒƒãƒˆã‚’è‡ªå‹•é¸æŠï¼‰",
            flat_options,
            index=1,  # "æ±ç”¨" ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            help="äºˆæ¸¬ã—ãŸã„ç‰©æ€§ã«å¿œã˜ã¦ã€æœ€é©ãªåˆ†å­è¨˜è¿°å­ã‚»ãƒƒãƒˆãŒè‡ªå‹•é¸æŠã•ã‚Œã¾ã™"
        )
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ˜ãƒƒãƒ€ãƒ¼ã¯é¸æŠã§ããªã„
        if selected_property_display.startswith("--"):
            target_property = "general"
        else:
            target_property = option_to_key.get(selected_property_display, "general")
        
        # è©³ç´°è¨­å®šï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ãƒƒã‚·ãƒ–é–‹ç¤ºï¼‰
        if show_advanced:
            st.divider()
            st.subheader("ğŸ”§ Advanced Settings")
            
            adv_col1, adv_col2 = st.columns(2)
            
            with adv_col1:
                cv_folds = st.slider("CV Folds", min_value=2, max_value=10, value=5)
                ml_task_type = st.selectbox("Task Type", ["regression", "classification"])
            
            with adv_col2:
                preprocessor = st.selectbox(
                    "Preprocessor Preset",
                    ["tree_optimized", "default", "robust", "normalized"],
                    help="tree_optimized is recommended for tree-based models"
                )
                use_smart_engine = st.checkbox(
                    "SmartFeatureEngineä½¿ç”¨",
                    value=True,
                    help="ç‰©æ€§Ã—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç‰¹æ€§ã«åŸºã¥ãæœ€é©ç‰¹å¾´é‡é¸æŠ"
                )
            
            # äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«é¸æŠ
            st.markdown("**ğŸ¤– äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰**")
            pretrained_col1, pretrained_col2 = st.columns(2)
            with pretrained_col1:
                use_unimol = st.checkbox("Uni-Molï¼ˆ3Dæ§‹é€ ï¼‰", value=False)
            with pretrained_col2:
                use_chemberta = st.checkbox("ChemBERTaï¼ˆSMILESï¼‰", value=False)
            
            pretrained_models = []
            if use_unimol:
                pretrained_models.append("unimol")
            if use_chemberta:
                pretrained_models.append("chemberta")
        else:
            cv_folds = 5
            ml_task_type = "regression"
            preprocessor = "tree_optimized"
            use_smart_engine = True
            pretrained_models = []
        
        submitted = st.form_submit_button("ğŸš€ Start Experiment", use_container_width=True)
        
        if submitted and dataset_options and selected_ds_label in dataset_options:
            _start_experiment(
                dataset_id=dataset_options[selected_ds_label],
                name=exp_name,
                features=features,
                model_type=model_type,
                cv_folds=cv_folds,
                task_type=ml_task_type,
                task_type_mode=selected_task_type,
                target_property=target_property,
                use_smart_engine=use_smart_engine,
                pretrained_models=pretrained_models,
            )
    
    # å®Ÿé¨“ä¸€è¦§
    st.subheader("ğŸ“‹ Recent Experiments")
    _display_experiments()


def _fetch_dataset_options() -> Dict[str, int]:
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å–å¾—"""
    options = {}
    try:
        res = requests.get(f"{API_URL}/datasets", timeout=10)
        if res.status_code == 200:
            for d in res.json():
                options[f"{d['id']}: {d['name']}"] = d['id']
    except Exception:
        pass
    return options


def _start_experiment(
    dataset_id: int,
    name: str,
    features: list,
    model_type: str,
    cv_folds: int,
    task_type: str,
    task_type_mode: str = "smiles_only",
    target_property: str = "general",
    use_smart_engine: bool = True,
    pretrained_models: list = None,
):
    """
    å®Ÿé¨“ã‚’é–‹å§‹
    
    Args:
        dataset_id: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆID
        name: å®Ÿé¨“å
        features: ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ
        model_type: ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—
        cv_folds: CVåˆ†å‰²æ•°
        task_type: ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ï¼ˆregression/classificationï¼‰
        task_type_mode: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ï¼ˆsmiles_only/tabular_only/mixture/smiles_tabularï¼‰
        target_property: ç›®çš„ç‰©æ€§ãƒ—ãƒªã‚»ãƒƒãƒˆ
        use_smart_engine: SmartFeatureEngineä½¿ç”¨ãƒ•ãƒ©ã‚°
        pretrained_models: ä½¿ç”¨ã™ã‚‹äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ
    """
    payload = {
        "dataset_id": dataset_id,
        "name": name or f"Experiment_{int(time.time())}",
        "features": features,
        "model_type": model_type,
        "cv_folds": cv_folds,
        "task_type": task_type,
        "task_type_mode": task_type_mode,
        "target_property": target_property,
        "use_smart_engine": use_smart_engine,
        "pretrained_models": pretrained_models or [],
    }
    
    try:
        with st.spinner("Starting experiment..."):
            res = requests.post(f"{API_URL}/experiments", json=payload, timeout=30)
        
        if res.status_code == 200:
            exp_data = res.json()
            st.success(f"âœ… Experiment started! ID: {exp_data['id']}")
            
            # è¨­å®šã‚µãƒãƒªãƒ¼è¡¨ç¤º
            with st.expander("ğŸ“‹ Experiment Settings", expanded=False):
                st.write(f"**Task Mode:** {task_type_mode}")
                st.write(f"**Target Property:** {target_property}")
                st.write(f"**Model:** {model_type}")
                st.write(f"**Features:** {', '.join(features)}")
                if pretrained_models:
                    st.write(f"**Pretrained Models:** {', '.join(pretrained_models)}")
            
            st.info("Check the Analysis tab for results once completed.")
        else:
            st.error(f"Failed: {res.text}")
    except Exception as e:
        st.error(f"Error: {e}")


def _display_experiments():
    """å®Ÿé¨“ä¸€è¦§ã‚’è¡¨ç¤º"""
    try:
        res = requests.get(f"{API_URL}/experiments", timeout=10)
        if res.status_code == 200:
            experiments = res.json()
            if experiments:
                df = pd.DataFrame(experiments)
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«è‰²ã‚’ä»˜ã‘ã‚‹
                st.dataframe(df, use_container_width=True)
    except Exception:
        pass


def render_analysis():
    """çµæœåˆ†æãƒšãƒ¼ã‚¸"""
    st.header("ğŸ“Š Results Analysis")
    
    # å®Ÿé¨“é¸æŠ
    exp_options = _fetch_experiment_options()
    
    if not exp_options:
        st.info("No experiments available. Create one first!")
        return
    
    selected_exp = st.selectbox("Select Experiment", list(exp_options.keys()))
    
    if not selected_exp:
        return
    
    exp_id = exp_options[selected_exp]
    
    try:
        res = requests.get(f"{API_URL}/experiments/{exp_id}", timeout=10)
        
        if res.status_code != 200:
            st.error("Failed to load experiment details")
            return
        
        exp = res.json()
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
        status = exp['status']
        if status == 'COMPLETED':
            st.success(f"Status: âœ… {status}")
        elif status == 'RUNNING':
            st.warning(f"Status: â³ {status}")
        elif status == 'FAILED':
            st.error(f"Status: âŒ {status}")
        else:
            st.info(f"Status: {status}")
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        if exp.get('metrics'):
            st.subheader("ğŸ“ˆ Validation Metrics")
            metrics = exp['metrics']
            
            # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆ
            if 'error' in metrics:
                st.error(f"Error: {metrics['error']}")
            else:
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ã‚«ãƒ©ãƒ ã§è¡¨ç¤º
                cols = st.columns(4)
                for i, (k, v) in enumerate(metrics.items()):
                    if isinstance(v, (int, float)) and not isinstance(v, bool):
                        cols[i % 4].metric(k, f"{v:.4f}")
        
        # å®Œäº†ã—ãŸå®Ÿé¨“ã®è©³ç´°
        if status == 'COMPLETED':
            st.divider()
            _render_completed_analysis(exp_id, exp)
            
    except Exception as e:
        st.error(f"Error: {e}")


def _fetch_experiment_options() -> Dict[str, int]:
    """å®Ÿé¨“ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å–å¾—"""
    options = {}
    try:
        res = requests.get(f"{API_URL}/experiments", timeout=10)
        if res.status_code == 200:
            for e in res.json():
                label = f"{e['id']}: {e['name']} ({e['status']})"
                options[label] = e['id']
    except Exception:
        pass
    return options


def _render_completed_analysis(exp_id: int, exp: Dict[str, Any]):
    """å®Œäº†ã—ãŸå®Ÿé¨“ã®åˆ†æã‚’è¡¨ç¤º"""
    # å¯è¦–åŒ–
    st.subheader("ğŸ¨ Global Explanations")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**SHAP Summary**")
        _display_artifact(exp_id, "shap_summary.png")
    
    with col2:
        st.markdown("**Feature Importance**")
        _display_artifact(exp_id, "feature_importance.png")
    
    col3, col4 = st.columns(2)
    
    with col3:
        st.markdown("**Learning Curve**")
        _display_artifact(exp_id, "learning_curve.png")
    
    with col4:
        st.markdown("**Predicted vs Actual**")
        _display_artifact(exp_id, "predicted_vs_actual.png")
    
    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–äºˆæ¸¬
    st.divider()
    st.subheader("ğŸ”® Interactive Prediction")
    
    smi_input = st.text_input("Enter SMILES", value="c1ccccc1", placeholder="e.g., CCO, c1ccccc1")
    
    if st.button("Predict", use_container_width=True):
        _run_prediction(exp_id, smi_input)


def _display_artifact(exp_id: int, filename: str):
    """ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’è¡¨ç¤º"""
    try:
        res = requests.get(f"{API_URL}/experiments/{exp_id}/artifacts/{filename}", timeout=10)
        if res.status_code == 200:
            st.image(res.content, use_container_width=True)
        else:
            st.info("Not available")
    except Exception:
        st.info("Not available")


def _run_prediction(exp_id: int, smiles: str):
    """äºˆæ¸¬ã‚’å®Ÿè¡Œ"""
    try:
        with st.spinner("Calculating..."):
            res = requests.post(
                f"{API_URL}/experiments/{exp_id}/predict",
                json={"smiles": smiles},
                timeout=30,
            )
        
        if res.status_code == 200:
            data = res.json()
            
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.metric("Prediction", f"{data['prediction']:.4f}")
            
            with col2:
                if data.get('shap_image'):
                    st.markdown("**SHAP Explanation**")
                    img_bytes = base64.b64decode(data['shap_image'])
                    st.image(img_bytes, use_container_width=True)
        else:
            st.error(f"Prediction failed: {res.text}")
            
    except Exception as e:
        st.error(f"Error: {e}")


def render_molecule_viewer():
    """åˆ†å­ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ãƒšãƒ¼ã‚¸"""
    st.header("ğŸ”¬ Molecule Viewer")
    st.markdown("SMILESã‹ã‚‰åˆ†å­æ§‹é€ ã¨ç‰©æ€§ã‚’è¡¨ç¤º")
    
    smiles_input = st.text_input("SMILESå…¥åŠ›", value="c1ccccc1", placeholder="ä¾‹: CCO, CC(=O)O")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if smiles_input:
            st.subheader("åˆ†å­æ§‹é€ ")
            try:
                # APIã‹ã‚‰åˆ†å­SVGã‚’å–å¾—
                svg_res = requests.get(f"{API_URL}/molecules/{smiles_input}/svg", timeout=10)
                if svg_res.status_code == 200:
                    st.image(svg_res.content, use_container_width=True)
                else:
                    st.warning("åˆ†å­ã®æç”»ã«å¤±æ•—ã—ã¾ã—ãŸ")
            except Exception as e:
                st.error(f"SVGå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    with col2:
        if smiles_input:
            st.subheader("ç‰©æ€§æƒ…å ±")
            try:
                props_res = requests.get(f"{API_URL}/molecules/{smiles_input}/properties", timeout=10)
                if props_res.status_code == 200:
                    props = props_res.json()
                    st.metric("åˆ†å­é‡", f"{props['molecular_weight']:.2f} g/mol")
                    st.metric("LogP", f"{props['logp']:.2f}")
                    st.metric("TPSA", f"{props['tpsa']:.2f} Ã…Â²")
                    
                    with st.expander("è©³ç´°æƒ…å ±"):
                        st.write(f"æ°´ç´ çµåˆãƒ‰ãƒŠãƒ¼: {props['hbd']}")
                        st.write(f"æ°´ç´ çµåˆã‚¢ã‚¯ã‚»ãƒ—ã‚¿ãƒ¼: {props['hba']}")
                        st.write(f"å›è»¢å¯èƒ½çµåˆ: {props['rotatable_bonds']}")
                        st.write(f"ç’°ã®æ•°: {props['num_rings']}")
                        st.write(f"åŸå­æ•°: {props['num_atoms']}")
                else:
                    st.warning("ç‰©æ€§è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            except Exception as e:
                st.error(f"ç‰©æ€§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    # SMILESæ¤œè¨¼
    st.divider()
    st.subheader("SMILESæ¤œè¨¼")
    validate_smiles = st.text_input("æ¤œè¨¼ã™ã‚‹SMILES", key="validate_smiles")
    if st.button("æ¤œè¨¼"):
        try:
            res = requests.post(f"{API_URL}/molecules/validate", json={"smiles": validate_smiles}, timeout=10)
            data = res.json()
            if data['valid']:
                st.success(f"âœ… æœ‰åŠ¹ãªSMILES - æ­£è¦åŒ–: `{data['canonical_smiles']}`")
            else:
                st.error(f"âŒ ç„¡åŠ¹ãªSMILES: {data['error']}")
        except Exception as e:
            st.error(f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")


def render_batch_predict():
    """ãƒãƒƒãƒäºˆæ¸¬ãƒšãƒ¼ã‚¸"""
    st.header("ğŸ“¦ ãƒãƒƒãƒäºˆæ¸¬")
    st.markdown("è¤‡æ•°ã®SMILESã«å¯¾ã—ã¦ä¸€æ‹¬ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ")
    
    # å®Ÿé¨“é¸æŠ
    exp_options = _fetch_experiment_options()
    completed_options = {k: v for k, v in exp_options.items() if "COMPLETED" in k}
    
    if not completed_options:
        st.warning("å®Œäº†ã—ãŸå®Ÿé¨“ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšå®Ÿé¨“ã‚’ä½œæˆãƒ»å®Œäº†ã•ã›ã¦ãã ã•ã„ã€‚")
        return
    
    selected_exp = st.selectbox("å®Ÿé¨“ã‚’é¸æŠ", list(completed_options.keys()))
    exp_id = completed_options.get(selected_exp)
    
    # å…¥åŠ›æ–¹å¼é¸æŠ
    input_method = st.radio("å…¥åŠ›æ–¹æ³•", ["ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›", "CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"], horizontal=True)
    
    smiles_list = []
    
    if input_method == "ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›":
        smiles_text = st.text_area(
            "SMILESãƒªã‚¹ãƒˆï¼ˆ1è¡Œã«1ã¤ï¼‰",
            value="CCO\nc1ccccc1\nCC(=O)O\nCCCCC",
            height=200
        )
        smiles_list = [s.strip() for s in smiles_text.split('\n') if s.strip()]
    else:
        uploaded = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆSMILESã‚«ãƒ©ãƒ ã‚’å«ã‚€ï¼‰", type=['csv'])
        if uploaded:
            df = pd.read_csv(uploaded)
            smiles_col = st.selectbox("SMILESã‚«ãƒ©ãƒ ", df.columns.tolist())
            smiles_list = df[smiles_col].dropna().tolist()
            st.info(f"{len(smiles_list)}ä»¶ã®SMILESã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    
    if smiles_list and st.button("ğŸš€ ãƒãƒƒãƒäºˆæ¸¬å®Ÿè¡Œ", use_container_width=True):
        with st.spinner(f"{len(smiles_list)}ä»¶ã®SMILESã‚’å‡¦ç†ä¸­..."):
            try:
                res = requests.post(
                    f"{API_URL}/experiments/{exp_id}/batch_predict",
                    json={"smiles_list": smiles_list},
                    timeout=120
                )
                
                if res.status_code == 200:
                    data = res.json()
                    predictions = data['predictions']
                    
                    st.success(f"âœ… {len(predictions)}ä»¶ã®äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    
                    # çµæœè¡¨ç¤º
                    result_df = pd.DataFrame(predictions)
                    st.dataframe(result_df, use_container_width=True)
                    
                    # CSVå‡ºåŠ›
                    csv = result_df.to_csv(index=False)
                    st.download_button(
                        "ğŸ“¥ çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        csv,
                        "predictions.csv",
                        "text/csv",
                        use_container_width=True
                    )
                    
                    # ç°¡æ˜“çµ±è¨ˆ
                    if 'prediction' in result_df.columns:
                        st.subheader("ğŸ“Š çµ±è¨ˆæƒ…å ±")
                        col1, col2, col3, col4 = st.columns(4)
                        col1.metric("å¹³å‡", f"{result_df['prediction'].mean():.4f}")
                        col2.metric("æ¨™æº–åå·®", f"{result_df['prediction'].std():.4f}")
                        col3.metric("æœ€å°", f"{result_df['prediction'].min():.4f}")
                        col4.metric("æœ€å¤§", f"{result_df['prediction'].max():.4f}")
                else:
                    st.error(f"ãƒãƒƒãƒäºˆæ¸¬å¤±æ•—: {res.text}")
                    
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    main()

