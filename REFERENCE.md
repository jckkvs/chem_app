# Chemical ML Platform - å®Œå…¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

**Version**: 1.0.0  
**Last Updated**: 2026-01-21

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€Chemical ML Platformã®å…¨æ©Ÿèƒ½ã€å…¨ãƒ¡ã‚½ãƒƒãƒ‰ã€å…¨ã‚³ãƒãƒ³ãƒ‰ã€å…¨å¼•æ•°ã‚’ç¶²ç¾…ã—ãŸåŒ…æ‹¬çš„ãªãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã§ã™ã€‚ç”ŸæˆAIã§ã®åˆ©ç”¨ã‚’æƒ³å®šã—ã€1ãƒ•ã‚¡ã‚¤ãƒ«ã§å®Œçµã—ã¦ã„ã¾ã™ã€‚

---

## ğŸ“‘ ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](#ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«)
3. [ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ](#ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ)
4. [ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹](#ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹)
5. [REST API](#rest-api)
6. [ç‰¹å¾´é‡æŠ½å‡ºAPI](#ç‰¹å¾´é‡æŠ½å‡ºapi)
7. [æ©Ÿæ¢°å­¦ç¿’API](#æ©Ÿæ¢°å­¦ç¿’api)
8. [å¯è¦–åŒ–API](#å¯è¦–åŒ–api)
9. [ãƒ—ãƒ©ã‚°ã‚¤ãƒ³API](#ãƒ—ãƒ©ã‚°ã‚¤ãƒ³api)
10. [è¨­å®š](#è¨­å®š)

---

## æ¦‚è¦

Chemical ML Platformã¯ã€åˆ†å­ç‰©æ€§äºˆæ¸¬ã®ãŸã‚ã®åŒ…æ‹¬çš„ãªæ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚

### ä¸»è¦æ©Ÿèƒ½
- **ç‰¹å¾´é‡æŠ½å‡º**: RDKitã€XTBã€UMAPã€Transformerï¼ˆTARTEï¼‰
- **æ©Ÿæ¢°å­¦ç¿’**: XGBoostã€LightGBMã€RandomForestã€AutoML
- **å¯è¦–åŒ–**: SHAPã€PDPã€åŒ–å­¦ç©ºé–“ãƒãƒƒãƒ—
- **API**: REST APIï¼ˆ16ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰
- **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰**: Djangoã€Streamlitã€PWA

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
```
Frontend (Django/Streamlit/PWA)
    â†“
API Layer (Django Ninja)
    â†“
Service Layer (Features/ML/Vis)
    â†“
Data Layer (SQLite/MLflow/Huey)
```

---

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### åŸºæœ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
# ä»®æƒ³ç’°å¢ƒä½œæˆ
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# å¿…é ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
pip install -r requirements.txt

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
python manage.py migrate
```

### ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆrequirements.txtï¼‰
```
# Core
Django>=4.2
django-ninja>=1.0
gunicorn>=21.0

# Data Science
pandas>=2.0
numpy>=1.24
scikit-learn>=1.3
xgboost>=2.0
lightgbm>=4.0

# Visualization
matplotlib>=3.7
seaborn>=0.12
shap>=0.44

# ML Tracking
mlflow>=2.10

# Chemistry
rdkit>=2023.09
umap-learn>=0.5

# Frontend
streamlit>=1.30
requests>=2.31

# Task Queue
huey>=2.4

# Testing
pytest>=7.4
pytest-django>=4.5
pytest-cov>=4.1
```

### ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
```bash
# XTBï¼ˆé‡å­åŒ–å­¦ï¼‰
conda install -c conda-forge xtb

# TARTEï¼ˆTransformerï¼‰
pip install tarte-ai

# Uni-Molï¼ˆ3DåŸ‹ã‚è¾¼ã¿ï¼‰
pip install unimol-tools

# ChemBERTa
pip install transformers torch
```

---

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
```bash
# Djangoé–‹ç™ºã‚µãƒ¼ãƒãƒ¼
python manage.py runserver
# â†’ http://localhost:8000

# Streamlit
cd frontend_streamlit
streamlit run app.py
# â†’ http://localhost:8501
```

### 2. Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ä½¿ç”¨
```python
from core.services.features import RDKitFeatureExtractor
from core.services.ml.pipeline import MLPipeline

# ç‰¹å¾´é‡æŠ½å‡º
extractor = RDKitFeatureExtractor()
X = extractor.transform(['CCO', 'c1ccccc1', 'CC(=O)O'])

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
pipeline = MLPipeline(
    feature_extractor=extractor,
    model_type='xgboost'
)
pipeline.fit(smiles_list, y_target)

# äºˆæ¸¬
predictions = pipeline.predict(['CN1C=NC2=C1C(=O)N(C(=O)N2C)C'])
```

---

## ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

### Djangoç®¡ç†ã‚³ãƒãƒ³ãƒ‰

#### `python manage.py runserver [port]`
é–‹ç™ºã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•

**å¼•æ•°**:
- `port` (optional): ãƒãƒ¼ãƒˆç•ªå·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8000ï¼‰

**ä¾‹**:
```bash
python manage.py runserver 8080
```

---

#### `python manage.py migrate`
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³**:
- `--fake`: å®Ÿéš›ã«ã¯ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã›ãšã€é©ç”¨æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯
- `--fake-initial`: åˆå›ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿fake
- `app_label`: ç‰¹å®šã‚¢ãƒ—ãƒªã®ã¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

**ä¾‹**:
```bash
python manage.py migrate core
python manage.py migrate --fake-initial
```

---

#### `python manage.py makemigrations [app_label]`
ãƒ¢ãƒ‡ãƒ«å¤‰æ›´ã‹ã‚‰ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ

**å¼•æ•°**:
- `app_label` (optional): ç‰¹å®šã‚¢ãƒ—ãƒªã®ã¿

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³**:
- `--dry-run`: å®Ÿéš›ã«ã¯ä½œæˆã›ãšã€å¤‰æ›´å†…å®¹ã‚’è¡¨ç¤º
- `--name NAME`: ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åã‚’æŒ‡å®š

**ä¾‹**:
```bash
python manage.py makemigrations core
python manage.py makemigrations --dry-run
```

---

#### `python manage.py createsuperuser`
ç®¡ç†è€…ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ä½œæˆ

**å¯¾è©±çš„å…¥åŠ›**:
- Username
- Email
- Password

---

#### `python manage.py shell`
Djangoã‚·ã‚§ãƒ«ã‚’èµ·å‹•ï¼ˆIPythonãŒå„ªå…ˆï¼‰

**ä¾‹**:
```bash
python manage.py shell
>>> from core.models import Dataset
>>> Dataset.objects.all()
```

---

#### `python manage.py test [path]`
ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ

**å¼•æ•°**:
- `path` (optional): ãƒ†ã‚¹ãƒˆãƒ‘ã‚¹

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³**:
- `--keepdb`: ãƒ†ã‚¹ãƒˆDBå‰Šé™¤ã‚’ã‚¹ã‚­ãƒƒãƒ—
- `--parallel N`: Nä¸¦åˆ—ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

**ä¾‹**:
```bash
python manage.py test core.tests
python manage.py test --parallel 4
```

---

### CLIãƒ„ãƒ¼ãƒ«ï¼ˆcli.pyï¼‰

#### `python cli.py extract [OPTIONS]`
ç‰¹å¾´é‡æŠ½å‡º

**å¼•æ•°**:
- `--input PATH`: å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«
- `--output PATH`: å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«
- `--smiles-col STR`: SMILESåˆ—åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'smiles'ï¼‰
- `--type STR`: ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—ï¼ˆrdkit/xtb/umaã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: rdkitï¼‰
- `--verbose`: è©³ç´°ãƒ­ã‚°

**ä¾‹**:
```bash
python cli.py extract --input data.csv --output features.csv --type rdkit
```

---

#### `python cli.py train [OPTIONS]`
ãƒ¢ãƒ‡ãƒ«å­¦ç¿’

**å¼•æ•°**:
- `--data PATH`: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿CSV
- `--target STR`: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—å
- `--model STR`: ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ï¼ˆxgboost/lightgbm/rfã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: xgboostï¼‰
- `--output PATH`: ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ
- `--cv INT`: äº¤å·®æ¤œè¨¼foldæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰

**ä¾‹**:
```bash
python cli.py train --data features.csv --target logS --model xgboost --output model.pkl
```

---

#### `python cli.py predict [OPTIONS]`
äºˆæ¸¬å®Ÿè¡Œ

**å¼•æ•°**:
- `--model PATH`: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
- `--input PATH`: å…¥åŠ›CSV
- `--output PATH`: å‡ºåŠ›CSV
- `--smiles-col STR`: SMILESåˆ—å

**ä¾‹**:
```bash
python cli.py predict --model model.pkl --input test.csv --output predictions.csv
```

---

## REST API

### ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

#### `GET /api/health`
ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "timestamp": "2026-01-21T10:00:00Z"
}
```

---

#### `GET /api/health/rdkit`
RDKitå‹•ä½œç¢ºèª

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:
```json
{
  "rdkit_available": true,
  "rdkit_version": "2023.09.1"
}
```

---

### åˆ†å­API

#### `POST /api/molecules/validate`
SMILESæ¤œè¨¼

**ãƒªã‚¯ã‚¨ã‚¹ãƒˆ**:
```json
{
  "smiles": "CCO"
}
```

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:
```json
{
  "valid": true,
  "canonical_smiles": "CCO",
  "errors": []
}
```

**ã‚¨ãƒ©ãƒ¼**:
```json
{
  "valid": false,
  "canonical_smiles": null,
  "errors": ["Invalid SMILES syntax"]
}
```

---

#### `GET /api/molecules/{smiles}/properties`
åˆ†å­ç‰©æ€§å–å¾—

**ãƒ‘ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `smiles`: SMILESæ–‡å­—åˆ—ï¼ˆURLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¿…è¦ï¼‰

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:
```json
{
  "smiles": "CCO",
  "properties": {
    "molecular_weight": 46.07,
    "logP": -0.07,
    "tpsa": 20.23,
    "num_h_donors": 1,
    "num_h_acceptors": 1,
    "num_rotatable_bonds": 0,
    "num_aromatic_rings": 0
  }
}
```

---

#### `GET /api/molecules/{smiles}/svg`
åˆ†å­æ§‹é€ SVGå–å¾—

**ãƒ‘ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `smiles`: SMILESæ–‡å­—åˆ—

**ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `width` (optional): å¹…ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 300ï¼‰
- `height` (optional): é«˜ã•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 300ï¼‰

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**: SVGç”»åƒï¼ˆimage/svg+xmlï¼‰

---

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆAPI

#### `GET /api/datasets`
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§å–å¾—

**ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `page` (optional): ãƒšãƒ¼ã‚¸ç•ªå·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1ï¼‰
- `per_page` (optional): 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20ï¼‰

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:
```json
{
  "data": [
    {
      "id": 1,
      "name": "Solubility Dataset",
      "row_count": 1000,
      "uploaded_at": "2026-01-20T10:00:00Z"
    }
  ],
  "pagination": {
    "page": 1,
    "per_page": 20,
    "total": 5,
    "pages": 1
  }
}
```

---

#### `POST /api/datasets`
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

**ãƒªã‚¯ã‚¨ã‚¹ãƒˆ**: multipart/form-data
- `name`: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå
- `file`: CSVãƒ•ã‚¡ã‚¤ãƒ«

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:
```json
{
  "id": 1,
  "name": "My Dataset",
  "row_count": 500,
  "uploaded_at": "2026-01-21T10:00:00Z"
}
```

---

#### `DELETE /api/datasets/{id}`
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‰Šé™¤

**ãƒ‘ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `id`: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆID

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**: 204 No Content

---

### å®Ÿé¨“API

#### `GET /api/experiments`
å®Ÿé¨“ä¸€è¦§å–å¾—

**ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `status` (optional): ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆpending/running/completed/failedï¼‰
- `model_type` (optional): ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿
- `page`, `per_page`: ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:
```json
{
  "data": [
    {
      "id": 1,
      "name": "XGBoost Solubility",
      "status": "completed",
      "model_type": "xgboost",
      "feature_type": "rdkit",
      "created_at": "2026-01-20T10:00:00Z"
    }
  ]
}
```

---

#### `POST /api/experiments`
å®Ÿé¨“ä½œæˆãƒ»é–‹å§‹

**ãƒªã‚¯ã‚¨ã‚¹ãƒˆ**:
```json
{
  "dataset_id": 1,
  "name": "My Experiment",
  "target_column": "logS",
  "feature_type": "rdkit",
  "model_type": "xgboost",
  "config": {
    "n_estimators": 100,
    "max_depth": 6,
    "learning_rate": 0.1
  }
}
```

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:
```json
{
  "id": 1,
  "name": "My Experiment",
  "status": "pending",
  "created_at": "2026-01-21T10:00:00Z"
}
```

---

#### `GET /api/experiments/{id}`
å®Ÿé¨“è©³ç´°å–å¾—

**ãƒ‘ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `id`: å®Ÿé¨“ID

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:
```json
{
  "id": 1,
  "name": "My Experiment",
  "status": "completed",
  "dataset": {
    "id": 1,
    "name": "Solubility Dataset"
  },
  "target_column": "logS",
  "feature_type": "rdkit",
  "model_type": "xgboost",
  "config": {...},
  "result": {
    "metrics": {
      "r2": 0.85,
      "mae": 0.23,
      "rmse": 0.31
    },
    "completed_at": "2026-01-21T10:05:00Z"
  }
}
```

---

#### `DELETE /api/experiments/{id}`
å®Ÿé¨“å‰Šé™¤

**ãƒ‘ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `id`: å®Ÿé¨“ID

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**: 204 No Content

---

#### `POST /api/experiments/{id}/predict`
å˜ä¸€äºˆæ¸¬

**ãƒ‘ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `id`: å®Ÿé¨“ID

**ãƒªã‚¯ã‚¨ã‚¹ãƒˆ**:
```json
{
  "smiles": "CCO"
}
```

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:
```json
{
  "smiles": "CCO",
  "prediction": 1.23,
  "uncertainty": 0.15
}
```

---

#### `POST /api/experiments/{id}/batch_predict`
ãƒãƒƒãƒäºˆæ¸¬

**ãƒ‘ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `id`: å®Ÿé¨“ID

**ãƒªã‚¯ã‚¨ã‚¹ãƒˆ**:
```json
{
  "smiles_list": ["CCO", "c1ccccc1", "CC(=O)O"]
}
```

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:
```json
{
  "predictions": [
    {"smiles": "CCO", "prediction": 1.23, "uncertainty": 0.15},
    {"smiles": "c1ccccc1", "prediction": 2.45, "uncertainty": 0.18},
    {"smiles": "CC(=O)O", "prediction": 0.87, "uncertainty": 0.12}
  ]
}
```

---

## ç‰¹å¾´é‡æŠ½å‡ºAPI

### BaseFeatureExtractor

å…¨ç‰¹å¾´é‡æŠ½å‡ºå™¨ã®åŸºåº•ã‚¯ãƒ©ã‚¹

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `__init__(**kwargs)`
åˆæœŸåŒ–

**å¼•æ•°**:
- `**kwargs`: æŠ½å‡ºå™¨å›ºæœ‰ã®è¨­å®š

---

##### `fit(smiles_list, y=None)`
æŠ½å‡ºå™¨ã‚’ãƒ‡ãƒ¼ã‚¿ã«ãƒ•ã‚£ãƒƒãƒˆï¼ˆStatefulã®å ´åˆï¼‰

**å¼•æ•°**:
- `smiles_list` (List[str]): SMILESãƒªã‚¹ãƒˆ
- `y` (Optional[Any]): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°

**æˆ»ã‚Šå€¤**: `Self`

---

##### `transform(smiles_list)`
SMILESã‚’ç‰¹å¾´é‡ã«å¤‰æ›

**å¼•æ•°**:
- `smiles_list` (List[str]): SMILESãƒªã‚¹ãƒˆ

**æˆ»ã‚Šå€¤**: `pd.DataFrame` - ç‰¹å¾´é‡DataFrame

---

##### `fit_transform(smiles_list, y=None)`
fit + transform ã‚’ä¸€åº¦ã«å®Ÿè¡Œ

**å¼•æ•°**:
- `smiles_list` (List[str]): SMILESãƒªã‚¹ãƒˆ
- `y` (Optional[Any]): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°

**æˆ»ã‚Šå€¤**: `pd.DataFrame`

---

##### `save(path)`
æŠ½å‡ºå™¨ã®çŠ¶æ…‹ã‚’ä¿å­˜

**å¼•æ•°**:
- `path` (str): ä¿å­˜å…ˆãƒ‘ã‚¹

---

##### `load(path)`
æŠ½å‡ºå™¨ã®çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã¿

**å¼•æ•°**:
- `path` (str): èª­ã¿è¾¼ã¿å…ƒãƒ‘ã‚¹

**æˆ»ã‚Šå€¤**: `Self`

---

#### ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£

##### `is_fitted`
ãƒ•ã‚£ãƒƒãƒˆæ¸ˆã¿ã‹

**æˆ»ã‚Šå€¤**: `bool`

---

##### `descriptor_names`
è¨˜è¿°å­åã®ãƒªã‚¹ãƒˆ

**æˆ»ã‚Šå€¤**: `List[str]`

---

##### `n_descriptors`
è¨˜è¿°å­ã®æ•°

**æˆ»ã‚Šå€¤**: `int`

---

### RDKitFeatureExtractor

RDKitåˆ†å­è¨˜è¿°å­æŠ½å‡º

#### åˆæœŸåŒ–
```python
from core.services.features import RDKitFeatureExtractor

extractor = RDKitFeatureExtractor(
    descriptor_types=['basic', 'topological', 'electronic'],
    use_3d=False
)
```

**å¼•æ•°**:
- `descriptor_types` (List[str]): è¨˜è¿°å­ã‚¿ã‚¤ãƒ—
  - `'basic'`: åŸºæœ¬è¨˜è¿°å­ï¼ˆMW, LogP, TPSAç­‰ï¼‰
  - `'topological'`: ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«è¨˜è¿°å­
  - `'electronic'`: é›»å­çš„è¨˜è¿°å­
  - `'fingerprint'`: ãƒ•ã‚£ãƒ³ã‚¬ãƒ¼ãƒ—ãƒªãƒ³ãƒˆ
- `use_3d` (bool): 3Dè¨˜è¿°å­ã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Falseï¼‰

#### ä½¿ç”¨ä¾‹
```python
extractor = RDKitFeatureExtractor()
features = extractor.transform(['CCO', 'c1ccccc1'])
print(features.shape)  # (2, N)
print(extractor.descriptor_names)  # ['MolWt', 'LogP', ...]
```

---

### XTBFeatureExtractor

XTBé‡å­åŒ–å­¦è¨˜è¿°å­æŠ½å‡º

#### åˆæœŸåŒ–
```python
from core.services.features import XTBFeatureExtractor

extractor = XTBFeatureExtractor(
    method='GFN2-xTB',
    optimize=True,
    charge=0,
    multiplicity=1
)
```

**å¼•æ•°**:
- `method` (str): è¨ˆç®—æ‰‹æ³•ï¼ˆ'GFN1-xTB', 'GFN2-xTB'ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'GFN2-xTB'ï¼‰
- `optimize` (bool): æ§‹é€ æœ€é©åŒ–ã‚’å®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
- `charge` (int): é›»è·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0ï¼‰
- `multiplicity` (int): å¤šé‡åº¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1ï¼‰

#### è¨ˆç®—ã•ã‚Œã‚‹è¨˜è¿°å­
- `total_energy`: å…¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆHartreeï¼‰
- `homo`: HOMOè»Œé“ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆeVï¼‰
- `lumo`: LUMOè»Œé“ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆeVï¼‰
- `gap`: HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ï¼ˆeVï¼‰
- `dipole`: åŒæ¥µå­ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆï¼ˆDebyeï¼‰
- `polarizability`: åˆ†æ¥µç‡

---

### UMAFeatureExtractor

UMAPæ¬¡å…ƒå‰Šæ¸›ã«ã‚ˆã‚‹ç‰¹å¾´é‡æŠ½å‡º

#### åˆæœŸåŒ–
```python
from core.services.features import UMAFeatureExtractor

extractor = UMAFeatureExtractor(
    n_components=10,
    n_neighbors=15,
    min_dist=0.1,
    metric='euclidean',
    base_features='rdkit'
)
```

**å¼•æ•°**:
- `n_components` (int): å‰Šæ¸›å¾Œã®æ¬¡å…ƒæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰
- `n_neighbors` (int): è¿‘å‚æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 15ï¼‰
- `min_dist` (float): æœ€å°è·é›¢ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.1ï¼‰
- `metric` (str): è·é›¢ãƒ¡ãƒˆãƒªãƒƒã‚¯ï¼ˆ'euclidean', 'manhattan'ç­‰ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'euclidean'ï¼‰
- `base_features` (str): å…ƒç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—ï¼ˆ'rdkit', 'fingerprint'ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'rdkit'ï¼‰

#### ä½¿ç”¨ä¾‹ï¼ˆè¦fitï¼‰
```python
extractor = UMAFeatureExtractor(n_components=5)
extractor.fit(smiles_train, y_train)  # å­¦ç¿’ãŒå¿…è¦
features = extractor.transform(smiles_test)
```

---

### TarteFeatureExtractor

Transformerï¼ˆTARTEï¼‰ã«ã‚ˆã‚‹ç‰¹å¾´é‡æŠ½å‡º

#### åˆæœŸåŒ–
```python
from core.services.features import TarteFeatureExtractor

extractor = TarteFeatureExtractor(
    mode='featurizer',
    model_name='default',
    n_features=128
)
```

**å¼•æ•°**:
- `mode` (str): å‹•ä½œãƒ¢ãƒ¼ãƒ‰
  - `'featurizer'`: ç‰¹å¾´é‡æŠ½å‡ºã®ã¿
  - `'finetuning'`: Finetuningå¾Œã®ç‰¹å¾´é‡
  - `'boosting'`: Boostingçµ±åˆ
- `model_name` (str): ãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'default'ï¼‰
- `n_features` (int): ç‰¹å¾´é‡æ¬¡å…ƒï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 128ï¼‰

**æ³¨æ„**: `tarte-ai`ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒå¿…è¦

---

### SmartFeatureEngine

ç‰©æ€§åˆ¥æœ€é©åŒ–ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ³

#### åˆæœŸåŒ–
```python
from core.services.features import SmartFeatureEngine

engine = SmartFeatureEngine(
    target_property='glass_transition',
    auto_select=True,
    selection_method='boruta',
    n_features=50
)
```

**å¼•æ•°**:
- `target_property` (str): ç‰©æ€§ã‚¿ã‚¤ãƒ—
  - å…‰å­¦: `'refractive_index'`, `'absorption'`, `'fluorescence'`
  - æ©Ÿæ¢°: `'glass_transition'`, `'tensile_strength'`, `'hardness'`
  - ç†±: `'melting_point'`, `'thermal_conductivity'`, `'heat_capacity'`
  - é›»æ°—: `'conductivity'`, `'dielectric_constant'`
  - åŒ–å­¦: `'solubility'`, `'reactivity'`, `'stability'`
  - è–¬ç†: `'bioavailability'`, `'toxicity'`, `'binding_affinity'`
- `auto_select` (bool): è‡ªå‹•ç‰¹å¾´é‡é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
- `selection_method` (str): é¸æŠæ‰‹æ³•ï¼ˆ'boruta', 'mrmr', 'rfe'ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'boruta'ï¼‰
- `n_features` (int): é¸æŠã™ã‚‹ç‰¹å¾´é‡æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ï¼‰

#### ä½¿ç”¨ä¾‹
```python
engine = SmartFeatureEngine(target_property='solubility')
result = engine.fit_transform(smiles_list, y_solubility)
print(result.keys())  # ['features', 'selected_indices', 'importances']
```

---

## æ©Ÿæ¢°å­¦ç¿’API

### BaseMLModel

å…¨MLãƒ¢ãƒ‡ãƒ«ã®åŸºåº•ã‚¯ãƒ©ã‚¹

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `__init__(**kwargs)`
åˆæœŸåŒ–

**å¼•æ•°**:
- `**kwargs`: ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

---

##### `fit(X, y, **kwargs)`
ãƒ¢ãƒ‡ãƒ«å­¦ç¿’

**å¼•æ•°**:
- `X` (pd.DataFrame | np.ndarray): ç‰¹å¾´é‡ï¼ˆN x Mï¼‰
- `y` (pd.Series | np.ndarray): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ï¼ˆN,ï¼‰
- `**kwargs`: è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆeval_set, early_stoppingç­‰ï¼‰

**æˆ»ã‚Šå€¤**: `Self`

---

##### `predict(X)`
äºˆæ¸¬å®Ÿè¡Œ

**å¼•æ•°**:
- `X` (pd.DataFrame | np.ndarray): ç‰¹å¾´é‡ï¼ˆN x Mï¼‰

**æˆ»ã‚Šå€¤**: `np.ndarray` - äºˆæ¸¬å€¤ï¼ˆN,ï¼‰

---

##### `predict_proba(X)`
ã‚¯ãƒ©ã‚¹ç¢ºç‡äºˆæ¸¬ï¼ˆåˆ†é¡ã®ã¿ï¼‰

**å¼•æ•°**:
- `X` (pd.DataFrame | np.ndarray): ç‰¹å¾´é‡

**æˆ»ã‚Šå€¤**: `Optional[np.ndarray]` - ã‚¯ãƒ©ã‚¹ç¢ºç‡ï¼ˆN x Cï¼‰ã€å›å¸°ã®å ´åˆNone

---

##### `save(path)`
ãƒ¢ãƒ‡ãƒ«ä¿å­˜

**å¼•æ•°**:
- `path` (str | Path): ä¿å­˜å…ˆãƒ‘ã‚¹

---

##### `load(path)`
ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿

**å¼•æ•°**:
- `path` (str | Path): èª­ã¿è¾¼ã¿å…ƒãƒ‘ã‚¹

**æˆ»ã‚Šå€¤**: `Self`

---

##### `get_params()`
ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—

**æˆ»ã‚Šå€¤**: `Dict[str, Any]`

---

##### `set_params(**params)`
ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š

**å¼•æ•°**:
- `**params`: æ›´æ–°ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

**æˆ»ã‚Šå€¤**: `Self`

---

### MLPipeline

æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

#### åˆæœŸåŒ–
```python
from core.services.ml.pipeline import MLPipeline
from core.services.features import RDKitFeatureExtractor

pipeline = MLPipeline(
    feature_extractor=RDKitFeatureExtractor(),
    model_type='xgboost',
    model_params={'n_estimators': 100, 'max_depth': 6},
    use_uncertainty=True,
    cv_folds=5
)
```

**å¼•æ•°**:
- `feature_extractor` (BaseFeatureExtractor): ç‰¹å¾´é‡æŠ½å‡ºå™¨
- `model_type` (str): ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ï¼ˆ'xgboost', 'lightgbm', 'randomforest'ï¼‰
- `model_params` (Dict): ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- `use_uncertainty` (bool): ä¸ç¢ºå®Ÿæ€§å®šé‡åŒ–ã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Falseï¼‰
- `cv_folds` (int): äº¤å·®æ¤œè¨¼foldæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `fit(smiles_list, y, validation_split=0.2)`
ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å­¦ç¿’

**å¼•æ•°**:
- `smiles_list` (List[str]): SMILES ãƒªã‚¹ãƒˆ
- `y` (np.ndarray): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
- `validation_split` (float): æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿æ¯”ç‡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.2ï¼‰

**æˆ»ã‚Šå€¤**: `Self`

---

##### `predict(smiles_list, return_uncertainty=False)`
äºˆæ¸¬å®Ÿè¡Œ

**å¼•æ•°**:
- `smiles_list` (List[str]): SMILESãƒªã‚¹ãƒˆ
- `return_uncertainty` (bool): ä¸ç¢ºå®Ÿæ€§ã‚‚è¿”ã™ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Falseï¼‰

**æˆ»ã‚Šå€¤**: 
- `return_uncertainty=False`: `np.ndarray` - äºˆæ¸¬å€¤
- `return_uncertainty=True`: `Tuple[np.ndarray, np.ndarray]` - (äºˆæ¸¬å€¤, ä¸ç¢ºå®Ÿæ€§)

---

##### `evaluate(smiles_test, y_test)`
ãƒ¢ãƒ‡ãƒ«è©•ä¾¡

**å¼•æ•°**:
- `smiles_test` (List[str]): ãƒ†ã‚¹ãƒˆSMILES
- `y_test` (np.ndarray): ãƒ†ã‚¹ãƒˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆ

**æˆ»ã‚Šå€¤**: `Dict[str, float]` - ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆr2, mae, rmseç­‰ï¼‰

---

##### `save(path)`
ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¿å­˜

**å¼•æ•°**:
- `path` (str): ä¿å­˜å…ˆãƒ‘ã‚¹

---

##### `load(path)`
ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³èª­ã¿è¾¼ã¿

**å¼•æ•°**:
- `path` (str): èª­ã¿è¾¼ã¿å…ƒãƒ‘ã‚¹

**æˆ»ã‚Šå€¤**: `MLPipeline`

---

### AutoMLOptimizer

Optunaã«ã‚ˆã‚‹è‡ªå‹•ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–

#### åˆæœŸåŒ–
```python
from core.services.ml.automl import AutoMLOptimizer

optimizer = AutoMLOptimizer(
    model_type='xgboost',
    n_trials=100,
    cv_folds=5,
    direction='maximize',
    metric='r2'
)
```

**å¼•æ•°**:
- `model_type` (str): ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—
- `n_trials` (int): è©¦è¡Œå›æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ï¼‰
- `cv_folds` (int): äº¤å·®æ¤œè¨¼foldæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
- `direction` (str): æœ€é©åŒ–æ–¹å‘ï¼ˆ'maximize', 'minimize'ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'maximize'ï¼‰
- `metric` (str): æœ€é©åŒ–ãƒ¡ãƒˆãƒªãƒƒã‚¯ï¼ˆ'r2', 'mae', 'rmse'ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'r2'ï¼‰

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `optimize(X, y, timeout=None)`
æœ€é©åŒ–å®Ÿè¡Œ

**å¼•æ•°**:
- `X` (pd.DataFrame): ç‰¹å¾´é‡
- `y` (np.ndarray): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
- `timeout` (Optional[int]): ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰

**æˆ»ã‚Šå€¤**: `Dict[str, Any]` - æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

---

##### `get_best_params()`
æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—

**æˆ»ã‚Šå€¤**: `Dict[str, Any]`

---

##### `get_study_summary()`
æœ€é©åŒ–å±¥æ­´ã‚µãƒãƒªãƒ¼

**æˆ»ã‚Šå€¤**: `pd.DataFrame`

---

## å¯è¦–åŒ–API

### BaseVisualizer

å…¨å¯è¦–åŒ–ã®åŸºåº•ã‚¯ãƒ©ã‚¹

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `__init__(**kwargs)`
åˆæœŸåŒ–

**å¼•æ•°**:
- `**kwargs`: å¯è¦–åŒ–å›ºæœ‰ã®è¨­å®š

---

##### `plot(*args, **kwargs)`
ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆ

**å¼•æ•°**:
- `*args`: ãƒ—ãƒ­ãƒƒãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
- `**kwargs`: ãƒ—ãƒ­ãƒƒãƒˆè¨­å®š

**æˆ»ã‚Šå€¤**: å›³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆmatplotlib.Figure, plotly.Figureç­‰ï¼‰

---

##### `save(fig, path, format=None, **kwargs)`
å›³ã‚’ä¿å­˜

**å¼•æ•°**:
- `fig`: å›³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
- `path` (str | Path): ä¿å­˜å…ˆãƒ‘ã‚¹
- `format` (Optional[str]): å‡ºåŠ›å½¢å¼ï¼ˆ'png', 'svg', 'html', 'json'ã€è‡ªå‹•åˆ¤å®šå¯ï¼‰
- `**kwargs`: ä¿å­˜ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆdpi, width, heightç­‰ï¼‰

---

##### `to_base64(fig, format='png')`
Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ–‡å­—åˆ—ã‚’ç”Ÿæˆ

**å¼•æ•°**:
- `fig`: å›³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
- `format` (str): å‡ºåŠ›å½¢å¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'png'ï¼‰

**æˆ»ã‚Šå€¤**: `str` - Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ–‡å­—åˆ—

---

### SHAPVisualizer

SHAPèª¬æ˜å¯è¦–åŒ–

#### åˆæœŸåŒ–
```python
from core.services.vis.shap_eng import SHAPVisualizer

viz = SHAPVisualizer(
    plot_type='waterfall',
    max_display=20
)
```

**å¼•æ•°**:
- `plot_type` (str): ãƒ—ãƒ­ãƒƒãƒˆã‚¿ã‚¤ãƒ—
  - `'waterfall'`: ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ«å›³
  - `'summary'`: ã‚µãƒãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ
  - `'dependence'`: ä¾å­˜æ€§ãƒ—ãƒ­ãƒƒãƒˆ
  - `'force'`: ãƒ•ã‚©ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
- `max_display` (int): æœ€å¤§è¡¨ç¤ºç‰¹å¾´é‡æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20ï¼‰

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `plot(model, X, feature_names=None, sample_index=None)`
SHAPå›³ç”Ÿæˆ

**å¼•æ•°**:
- `model`: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
- `X` (pd.DataFrame): ç‰¹å¾´é‡
- `feature_names` (Optional[List[str]]): ç‰¹å¾´é‡å
- `sample_index` (Optional[int]): ã‚µãƒ³ãƒ—ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆwaterfall/forceç”¨ï¼‰

**æˆ»ã‚Šå€¤**: matplotlib.Figure

---

### PDPVisualizer

Partial Dependence Plotå¯è¦–åŒ–

#### åˆæœŸåŒ–
```python
from core.services.vis.pdp_eng import PDPVisualizer

viz = PDPVisualizer(
    feature_names=['MolWt', 'LogP'],
    kind='average'
)
```

**å¼•æ•°**:
- `feature_names` (List[str]): è¡¨ç¤ºã™ã‚‹ç‰¹å¾´é‡å
- `kind` (str): ãƒ—ãƒ­ãƒƒãƒˆã‚¿ã‚¤ãƒ—ï¼ˆ'average', 'individual', 'both'ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'average'ï¼‰

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `plot(model, X, feature_idx, grid_resolution=100)`
PDPç”Ÿæˆ

**å¼•æ•°**:
- `model`: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
- `X` (pd.DataFrame): ç‰¹å¾´é‡
- `feature_idx` (int | str): ç‰¹å¾´é‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¾ãŸã¯åå‰
- `grid_resolution` (int): ã‚°ãƒªãƒƒãƒ‰è§£åƒåº¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ï¼‰

**æˆ»ã‚Šå€¤**: matplotlib.Figure

---

### ChemSpaceVisualizer

åŒ–å­¦ç©ºé–“ãƒãƒƒãƒ—å¯è¦–åŒ–

#### åˆæœŸåŒ–
```python
from core.services.vis.chem_space import ChemSpaceVisualizer

viz = ChemSpaceVisualizer(
    method='umap',
    n_components=2,
    color_by='target'
)
```

**å¼•æ•°**:
- `method` (str): æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ï¼ˆ'umap', 'tsne', 'pca'ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'umap'ï¼‰
- `n_components` (int): å‰Šæ¸›å¾Œæ¬¡å…ƒï¼ˆ2 or 3ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2ï¼‰
- `color_by` (str): è‰²åˆ†ã‘åŸºæº–ï¼ˆ'target', 'cluster', 'none'ï¼‰

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `plot(features, y=None, smiles=None)`
åŒ–å­¦ç©ºé–“ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆ

**å¼•æ•°**:
- `features` (pd.DataFrame): ç‰¹å¾´é‡
- `y` (Optional[np.ndarray]): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ï¼ˆè‰²åˆ†ã‘ç”¨ï¼‰
- `smiles` (Optional[List[str]]): SMILESï¼ˆãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ—ç”¨ï¼‰

**æˆ»ã‚Šå€¤**: plotly.Figureï¼ˆã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ï¼‰

---

### MoleculeVisualizer

åˆ†å­æ§‹é€ å¯è¦–åŒ–

#### ä½¿ç”¨ä¾‹
```python
from core.services.vis.mol_viewer import MoleculeVisualizer

viz = MoleculeVisualizer()
fig = viz.plot('CCO', size=(300, 300), highlight_atoms=[0, 1])
viz.save(fig, 'ethanol.png)
```

**plot()å¼•æ•°**:
- `smiles` (str): SMILES
- `size` (Tuple[int, int]): ç”»åƒã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: (300, 300)ï¼‰
- `highlight_atoms` (Optional[List[int]]): ãƒã‚¤ãƒ©ã‚¤ãƒˆã™ã‚‹åŸå­ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

---

## ãƒ—ãƒ©ã‚°ã‚¤ãƒ³API

### Plugin

ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å®šç¾©ã‚¯ãƒ©ã‚¹

#### åˆæœŸåŒ–
```python
from core.services.plugin import Plugin

plugin = Plugin(
    name="my_plugin",
    version="1.0.0",
    description="ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ©ã‚°ã‚¤ãƒ³",
    hooks={
        "on_prediction": my_prediction_hook,
        "on_training": my_training_hook
    },
    author="Your Name",
    license="MIT",
    requires=["rdkit>=2023.09"],
    config={"threshold": 0.8}
)
```

**å¼•æ•°**:
- `name` (str): ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å
- `version` (str): ãƒãƒ¼ã‚¸ãƒ§ãƒ³
- `description` (str): èª¬æ˜
- `hooks` (Dict[str, Callable]): ãƒ•ãƒƒã‚¯é–¢æ•°
- `enabled` (bool): æœ‰åŠ¹/ç„¡åŠ¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
- `author` (Optional[str]): ä½œè€…
- `license` (Optional[str]): ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
- `requires` (List[str]): ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
- `config` (Dict[str, Any]): è¨­å®š

---

### PluginManager

ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ç®¡ç†

#### åˆæœŸåŒ–
```python
from core.services.plugin import PluginManager

pm = PluginManager(
    auto_discover=True,
    plugin_dir='plugins'
)
```

**å¼•æ•°**:
- `auto_discover` (bool): è‡ªå‹•æ¤œå‡ºã‚’æœ‰åŠ¹åŒ–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Falseï¼‰
- `plugin_dir` (str): ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'plugins'ï¼‰

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `register(plugin)`
ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ç™»éŒ²

**å¼•æ•°**:
- `plugin` (Plugin): ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

---

##### `unregister(name)`
ãƒ—ãƒ©ã‚°ã‚¤ãƒ³è§£é™¤

**å¼•æ•°**:
- `name` (str): ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å

**æˆ»ã‚Šå€¤**: `bool` - æˆåŠŸæ™‚True

---

##### `execute_hook(hook_name, *args, **kwargs)`
ãƒ•ãƒƒã‚¯å®Ÿè¡Œ

**å¼•æ•°**:
- `hook_name` (str): ãƒ•ãƒƒã‚¯å
- `*args`, `**kwargs`: ãƒ•ãƒƒã‚¯é–¢æ•°ã«æ¸¡ã™å¼•æ•°

**æˆ»ã‚Šå€¤**: `List[Any]` - å„ãƒ•ãƒƒã‚¯é–¢æ•°ã®æˆ»ã‚Šå€¤ãƒªã‚¹ãƒˆ

---

##### `discover_plugins(plugin_dir=None)`
ãƒ—ãƒ©ã‚°ã‚¤ãƒ³è‡ªå‹•æ¤œå‡º

**å¼•æ•°**:
- `plugin_dir` (Optional[str]): æ¤œå‡ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

**æˆ»ã‚Šå€¤**: `List[Plugin]` - æ¤œå‡ºã•ã‚ŒãŸãƒ—ãƒ©ã‚°ã‚¤ãƒ³

---

##### `list_plugins()`
ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ä¸€è¦§

**æˆ»ã‚Šå€¤**: `List[Dict[str, Any]]` - ãƒ—ãƒ©ã‚°ã‚¤ãƒ³æƒ…å ±ãƒªã‚¹ãƒˆ

---

##### `enable(name)` / `disable(name)`
ãƒ—ãƒ©ã‚°ã‚¤ãƒ³æœ‰åŠ¹åŒ–/ç„¡åŠ¹åŒ–

**å¼•æ•°**:
- `name` (str): ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å

**æˆ»ã‚Šå€¤**: `bool` - æˆåŠŸæ™‚True

---

### åˆ©ç”¨å¯èƒ½ãªãƒ•ãƒƒã‚¯

#### `on_prediction`
äºˆæ¸¬å®Ÿè¡Œå¾Œã«å‘¼ã°ã‚Œã‚‹

**ã‚·ã‚°ãƒãƒãƒ£**:
```python
def on_prediction(smiles: str, prediction: float, **kwargs) -> float:
    # å‡¦ç†
    return adjusted_prediction
```

---

#### `on_training`
å­¦ç¿’å®Œäº†å¾Œã«å‘¼ã°ã‚Œã‚‹

**ã‚·ã‚°ãƒãƒãƒ£**:
```python
def on_training(experiment, **kwargs) -> None:
    # å‡¦ç†ï¼ˆä¾‹: é€šçŸ¥é€ä¿¡ï¼‰
    pass
```

---

#### `on_feature_extraction`
ç‰¹å¾´é‡æŠ½å‡ºå‰ã«å‘¼ã°ã‚Œã‚‹

**ã‚·ã‚°ãƒãƒãƒ£**:
```python
def on_feature_extraction(smiles_list: List[str]) -> List[str]:
    # å‰å‡¦ç†
    return processed_smiles_list
```

---

#### `on_error`
ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«å‘¼ã°ã‚Œã‚‹

**ã‚·ã‚°ãƒãƒãƒ£**:
```python
def on_error(error: Exception, context: dict) -> None:
    # ã‚¨ãƒ©ãƒ¼å‡¦ç†ï¼ˆä¾‹: ãƒ­ã‚®ãƒ³ã‚°ã€é€šçŸ¥ï¼‰
    pass
```

---

## è¨­å®š

### Djangoè¨­å®šï¼ˆchem_ml_project/settings.pyï¼‰

#### DATABASE
```python
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': BASE_DIR / 'db.sqlite3',
    }
}
```

#### INSTALLED_APPS
```python
INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    # ...
    'core',
    'huey.contrib.djhuey',
]
```

#### REST_FRAMEWORK
```python
REST_FRAMEWORK = {
    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',
    'PAGE_SIZE': 20
}
```

---

### MLflowè¨­å®š

#### ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°URI
```python
import mlflow
mlflow.set_tracking_uri('sqlite:///mlflow.db')
mlflow.set_experiment('chemical_ml')
```

#### ä½¿ç”¨ä¾‹
```python
with mlflow.start_run():
    mlflow.log_params(model.get_params())
    mlflow.log_metrics({'r2': 0.85, 'mae': 0.23})
    mlflow.sklearn.log_model(model, "model")
```

---

### Hueyè¨­å®šï¼ˆã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ï¼‰

```python
from huey import SqliteHuey

huey = SqliteHuey(filename='huey_db.sqlite3')

@huey.task()
def train_model_async(experiment_id):
    # éåŒæœŸå­¦ç¿’å‡¦ç†
    pass
```

---

## ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### æ¨™æº–ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰

| ã‚³ãƒ¼ãƒ‰ | èª¬æ˜ |
|--------|------|
| `ERR_1001` | ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ |
| `ERR_1002` | å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ è½ |
| `ERR_2001` | ãƒªã‚½ãƒ¼ã‚¹æœªç™ºè¦‹ |
| `ERR_2002` | ãƒªã‚½ãƒ¼ã‚¹é‡è¤‡ |
| `ERR_3001` | ç„¡åŠ¹ãªSMILES |
| `ERR_3002` | åˆ†å­ã‚µã‚¤ã‚ºè¶…é |
| `ERR_4001` | ãƒ¢ãƒ‡ãƒ«æœªå­¦ç¿’ |
| `ERR_4002` | äºˆæ¸¬å¤±æ•— |

### ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¾‹
```json
{
  "error": {
    "code": "ERR_3001",
    "message": "Invalid SMILES syntax",
    "details": {
      "smiles": "INVALID",
      "position": 3
    },
    "timestamp": "2026-01-21T10:00:00Z"
  }
}
```

---

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°

#### RDKitåˆ†å­ã‚­ãƒ£ãƒƒã‚·ãƒ¥
```python
from core.services.cache import MoleculeCache

cache = MoleculeCache(maxsize=1000)
mol = cache.get_or_create('CCO')
```

#### ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥
```python
from core.services.feature_store import FeatureStore

store = FeatureStore()
store.save_features('dataset_1', features_df)
features = store.load_features('dataset_1')
```

---

### ãƒãƒƒãƒå‡¦ç†

```python
from core.services.utils.batch_processing import batch_process

results = batch_process(
    smiles_list,
    process_func=extract_features,
    batch_size=100,
    n_jobs=4
)
```

---

## ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

### SMILESæ¤œè¨¼
```python
from core.services.validation import validate_smiles

is_valid, error = validate_smiles('CCO')
if not is_valid:
    raise ValueError(error)
```

### ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¤œè¨¼
```python
from core.services.validation import validate_csv_file

is_valid, error = validate_csv_file(uploaded_file)
```

---

## ä»˜éŒ²

### ç”¨èªé›†

- **SMILES**: åˆ†å­æ§‹é€ ã‚’æ–‡å­—åˆ—ã§è¡¨ç¾ã™ã‚‹è¨˜æ³•
- **è¨˜è¿°å­**: åˆ†å­ã®ç‰¹å¾´ã‚’æ•°å€¤åŒ–ã—ãŸã‚‚ã®
- **HOMO/LUMO**: æœ€é«˜è¢«å è»Œé“/æœ€ä½ç©ºè»Œé“
- **UMAP**: æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•
- **SHAP**: SHapley Additive exPlanationsã®ç•¥ã€èª¬æ˜å¯èƒ½AIæ‰‹æ³•

---

### å‚è€ƒãƒªãƒ³ã‚¯

- **GitHub**: https://github.com/jckkvs/chem_app
- **RDKit Documentation**: https://www.rdkit.org/docs/
- **XTB Documentation**: https://xtb-docs.readthedocs.io/
- **MLflow Documentation**: https://mlflow.org/docs/latest/

---

**ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ç”ŸæˆAIã§ã®åˆ©ç”¨ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚**
**å…¨APIã€å…¨ãƒ¡ã‚½ãƒƒãƒ‰ã€å…¨å¼•æ•°ã‚’ç¶²ç¾…ã—ãŸå®Œå…¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã§ã™ã€‚**
