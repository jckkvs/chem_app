"""
Chemical ML Platform - Django Ninja API

Implements: F-API-001
è¨­è¨ˆæ€æƒ³:
- RESTful APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
- é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- å‹å®‰å…¨ãªã‚¹ã‚­ãƒ¼ãƒ
"""

from __future__ import annotations

import base64
import io
import logging
import mimetypes
import os
from datetime import datetime
from typing import Dict, List, Optional, Union

import matplotlib.pyplot as plt
import mlflow
import pandas as pd
from django.conf import settings
from django.http import Http404, HttpResponse
from django.shortcuts import get_object_or_404
from ninja import File, Form, NinjaAPI, Schema, UploadedFile

from .models import Dataset, Experiment

logger = logging.getLogger(__name__)

# APIåˆæœŸåŒ–
api = NinjaAPI(
    title="ChemML API",
    version="2.0",
    urls_namespace="chem_api",
)


# --- Health Check ---

@api.get("/health")
def health_check(request):
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆé‹ç”¨ç›£è¦–ç”¨ï¼‰"""
    import sys

    from django.db import connection
    
    status = {"status": "healthy", "version": "2.0"}
    
    # DBæ¥ç¶šãƒã‚§ãƒƒã‚¯
    try:
        with connection.cursor() as cursor:
            cursor.execute("SELECT 1")
        status["database"] = "connected"
    except Exception as e:
        status["database"] = f"error: {e}"
        status["status"] = "degraded"
    
    # Python/Djangoæƒ…å ±
    status["python"] = sys.version.split()[0]
    
    return status


@api.get("/health/rdkit")
def health_rdkit(request):
    """RDKitå‹•ä½œç¢ºèª"""
    try:
        from rdkit import Chem, rdBase
        mol = Chem.MolFromSmiles("CCO")
        return {
            "status": "ok",
            "rdkit_version": rdBase.rdkitVersion,
            "test_smiles": "CCO",
            "test_valid": mol is not None
        }
    except Exception as e:
        return {"status": "error", "error": str(e)}


# --- Schemas ---

class DatasetOut(Schema):
    id: int
    name: str
    file_path: str
    smiles_col: str
    target_col: str


class ExperimentIn(Schema):
    dataset_id: int
    name: str
    features: List[str] = ['rdkit']
    model_type: str = 'lightgbm'


class ExperimentOut(Schema):
    id: int
    name: str
    status: str
    config: Dict
    metrics: Optional[Dict] = None
    created_at: datetime


class PredictionIn(Schema):
    smiles: str


class PredictionOut(Schema):
    prediction: float
    shap_image: Optional[str] = None


class ErrorOut(Schema):
    detail: str


class MoleculeValidation(Schema):
    smiles: str
    valid: bool
    canonical_smiles: Optional[str] = None
    error: Optional[str] = None


class MoleculeProperties(Schema):
    smiles: str
    molecular_weight: float
    logp: float
    tpsa: float
    hbd: int
    hba: int
    rotatable_bonds: int
    num_rings: int
    num_atoms: int


class BatchPredictionIn(Schema):
    smiles_list: List[str]


class BatchPredictionOut(Schema):
    predictions: List[Dict]


class SuccessOut(Schema):
    success: bool
    message: str


# --- Molecule Endpoints ---

@api.post("/molecules/validate", response=MoleculeValidation)
def validate_molecule(request, payload: PredictionIn):
    """
    SMILESã®æ¤œè¨¼ã¨æ­£è¦åŒ–
    """
    from rdkit import Chem
    
    mol = Chem.MolFromSmiles(payload.smiles)
    if mol is None:
        return {
            "smiles": payload.smiles,
            "valid": False,
            "canonical_smiles": None,
            "error": "Invalid SMILES structure",
        }
    
    return {
        "smiles": payload.smiles,
        "valid": True,
        "canonical_smiles": Chem.MolToSmiles(mol),
        "error": None,
    }


@api.get("/molecules/{smiles}/properties", response={200: MoleculeProperties, 400: ErrorOut})
def get_molecule_properties(request, smiles: str):
    """
    åˆ†å­ã®ç‰©æ€§æƒ…å ±ã‚’å–å¾—
    """
    try:
        from rdkit import Chem
        from rdkit.Chem import Descriptors, Lipinski
        
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return 400, {"detail": "Invalid SMILES"}
        
        return {
            "smiles": smiles,
            "molecular_weight": round(Descriptors.MolWt(mol), 2),
            "logp": round(Descriptors.MolLogP(mol), 2),
            "tpsa": round(Descriptors.TPSA(mol), 2),
            "hbd": Lipinski.NumHDonors(mol),
            "hba": Lipinski.NumHAcceptors(mol),
            "rotatable_bonds": Lipinski.NumRotatableBonds(mol),
            "num_rings": Descriptors.RingCount(mol),
            "num_atoms": mol.GetNumAtoms(),
        }
    except Exception as e:
        logger.error(f"Property calculation failed: {e}")
        return 400, {"detail": str(e)}


@api.get("/molecules/{smiles}/svg")
def get_molecule_svg(request, smiles: str, width: int = 300, height: int = 200):
    """
    åˆ†å­ã®SVGç”»åƒã‚’å–å¾—
    """
    try:
        from rdkit import Chem
        from rdkit.Chem import Draw
        
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return HttpResponse("<svg></svg>", content_type="image/svg+xml")
        
        svg = Draw.MolToImage(mol, size=(width, height))
        
        # SVGå½¢å¼ã§ç”Ÿæˆ
        from rdkit.Chem.Draw import rdMolDraw2D
        drawer = rdMolDraw2D.MolDraw2DSVG(width, height)
        drawer.DrawMolecule(mol)
        drawer.FinishDrawing()
        svg_text = drawer.GetDrawingText()
        
        return HttpResponse(svg_text, content_type="image/svg+xml")
        
    except Exception as e:
        logger.error(f"SVG generation failed: {e}")
        return HttpResponse(f"<svg><text>{e}</text></svg>", content_type="image/svg+xml")


# --- Similarity Search ---

class SimilaritySearchIn(Schema):
    query_smiles: str
    target_smiles_list: List[str]
    threshold: float = 0.7  # Tanimotoé¡ä¼¼åº¦é–¾å€¤
    top_k: int = 10  # ä¸Šä½kä»¶


class SimilarityResult(Schema):
    smiles: str
    similarity: float


class SimilaritySearchOut(Schema):
    query_smiles: str
    results: List[SimilarityResult]
    threshold: float
    total_searched: int


@api.post("/molecules/similarity", response={200: SimilaritySearchOut, 400: ErrorOut})
def similarity_search(request, payload: SimilaritySearchIn):
    """
    åˆ†å­é¡ä¼¼åº¦æ¤œç´¢ï¼ˆTanimotoä¿‚æ•°ï¼‰
    
    ã‚¯ã‚¨ãƒªSMILESã«å¯¾ã—ã¦ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒªã‚¹ãƒˆã‹ã‚‰é¡ä¼¼åº¦ãŒé–¾å€¤ä»¥ä¸Šã®åˆ†å­ã‚’æ¤œç´¢
    """
    try:
        from rdkit import Chem
        from rdkit.Chem import AllChem, DataStructs

        # ã‚¯ã‚¨ãƒªåˆ†å­ã®ãƒ•ã‚£ãƒ³ã‚¬ãƒ¼ãƒ—ãƒªãƒ³ãƒˆç”Ÿæˆ
        query_mol = Chem.MolFromSmiles(payload.query_smiles)
        if query_mol is None:
            return 400, {"detail": "Invalid query SMILES"}
        
        query_fp = AllChem.GetMorganFingerprintAsBitVect(query_mol, radius=2, nBits=2048)
        
        # å„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã®é¡ä¼¼åº¦è¨ˆç®—
        results = []
        for target_smiles in payload.target_smiles_list:
            try:
                target_mol = Chem.MolFromSmiles(target_smiles)
                if target_mol is None:
                    continue
                
                target_fp = AllChem.GetMorganFingerprintAsBitVect(target_mol, radius=2, nBits=2048)
                similarity = DataStructs.TanimotoSimilarity(query_fp, target_fp)
                
                if similarity >= payload.threshold:
                    results.append({
                        "smiles": target_smiles,
                        "similarity": round(similarity, 4)
                    })
            except Exception:
                continue
        
        # é¡ä¼¼åº¦ã§é™é †ã‚½ãƒ¼ãƒˆã€ä¸Šä½kä»¶ã‚’è¿”ã™
        results.sort(key=lambda x: x["similarity"], reverse=True)
        results = results[:payload.top_k]
        
        return {
            "query_smiles": payload.query_smiles,
            "results": results,
            "threshold": payload.threshold,
            "total_searched": len(payload.target_smiles_list)
        }
        
    except Exception as e:
        logger.error(f"Similarity search failed: {e}")
        return 400, {"detail": str(e)}


@api.get("/molecules/{smiles}/fingerprint")
def get_fingerprint(request, smiles: str, radius: int = 2, n_bits: int = 2048):
    """
    åˆ†å­ã®ãƒ•ã‚£ãƒ³ã‚¬ãƒ¼ãƒ—ãƒªãƒ³ãƒˆã‚’å–å¾—ï¼ˆMorgan/ECFPï¼‰
    """
    try:
        from rdkit import Chem
        from rdkit.Chem import AllChem
        
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return {"error": "Invalid SMILES"}
        
        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=n_bits)
        
        # ãƒ“ãƒƒãƒˆä½ç½®ã®ãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã™
        on_bits = list(fp.GetOnBits())
        
        return {
            "smiles": smiles,
            "fingerprint_type": f"Morgan (radius={radius})",
            "n_bits": n_bits,
            "on_bits": on_bits,
            "bit_count": len(on_bits),
            "density": round(len(on_bits) / n_bits, 4)
        }
        
    except Exception as e:
        return {"error": str(e)}


# --- Dataset Endpoints ---

@api.post("/datasets", response={200: DatasetOut, 400: ErrorOut})
def upload_dataset(
    request,
    file: UploadedFile = File(...),
    name: str = Form(...),
    smiles_col: str = Form("SMILES"),
    target_col: str = Form("target"),
):
    """
    ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    """
    try:
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        upload_dir = os.path.join(settings.BASE_DIR, 'uploads')
        os.makedirs(upload_dir, exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        file_path = os.path.join(upload_dir, file.name)
        with open(file_path, 'wb+') as destination:
            for chunk in file.chunks():
                destination.write(chunk)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç™»éŒ²
        dataset = Dataset.objects.create(
            name=name,
            file_path=file_path,
            smiles_col=smiles_col,
            target_col=target_col,
        )
        
        logger.info(f"Dataset uploaded: {name} ({file_path})")
        return dataset
        
    except Exception as e:
        logger.error(f"Dataset upload failed: {e}")
        return 400, {"detail": str(e)}


@api.get("/datasets", response=List[DatasetOut])
def list_datasets(request):
    """
    ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§ã‚’å–å¾—
    """
    return Dataset.objects.all()


@api.delete("/datasets/{dataset_id}", response={200: SuccessOut, 404: ErrorOut})
def delete_dataset(request, dataset_id: int):
    """
    ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å‰Šé™¤
    """
    try:
        dataset = get_object_or_404(Dataset, id=dataset_id)
        name = dataset.name
        file_path = dataset.file_path
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        if os.path.exists(file_path):
            os.remove(file_path)
        
        # DBå‰Šé™¤
        dataset.delete()
        
        logger.info(f"Dataset deleted: {name}")
        return {"success": True, "message": f"Dataset '{name}' deleted"}
        
    except Http404:
        return 404, {"detail": "Dataset not found"}
    except Exception as e:
        logger.error(f"Dataset deletion failed: {e}")
        return 404, {"detail": str(e)}


# --- Experiment Endpoints ---

@api.post("/experiments", response={200: ExperimentOut, 400: ErrorOut})
def create_experiment(request, payload: ExperimentIn):
    """
    æ–°ã—ã„å®Ÿé¨“ã‚’ä½œæˆã—ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§è¨“ç·´ã‚’é–‹å§‹
    """
    try:
        dataset = get_object_or_404(Dataset, id=payload.dataset_id)
        
        config = {
            "features": payload.features,
            "model_type": payload.model_type,
        }
        
        experiment = Experiment.objects.create(
            dataset=dataset,
            name=payload.name,
            status='PENDING',
            config=config,
        )
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯èµ·å‹•
        from core.tasks import run_training_task
        run_training_task(experiment.id)
        
        logger.info(f"Experiment created: {experiment.name} (ID={experiment.id})")
        return experiment
        
    except Exception as e:
        logger.error(f"Experiment creation failed: {e}")
        return 400, {"detail": str(e)}


@api.get("/experiments", response=List[ExperimentOut])
def list_experiments(request):
    """
    å®Ÿé¨“ä¸€è¦§ã‚’å–å¾—
    """
    return Experiment.objects.all().order_by('-created_at')


@api.get("/experiments/{experiment_id}", response={200: ExperimentOut, 404: ErrorOut})
def get_experiment(request, experiment_id: int):
    """
    å®Ÿé¨“è©³ç´°ã‚’å–å¾—
    """
    experiment = get_object_or_404(Experiment, id=experiment_id)
    return experiment


@api.delete("/experiments/{experiment_id}", response={200: SuccessOut, 404: ErrorOut})
def delete_experiment(request, experiment_id: int):
    """
    å®Ÿé¨“ã‚’å‰Šé™¤
    """
    try:
        experiment = get_object_or_404(Experiment, id=experiment_id)
        name = experiment.name
        experiment.delete()
        
        logger.info(f"Experiment deleted: {name}")
        return {"success": True, "message": f"Experiment '{name}' deleted"}
        
    except Http404:
        return 404, {"detail": "Experiment not found"}
    except Exception as e:
        logger.error(f"Experiment deletion failed: {e}")
        return 404, {"detail": str(e)}


@api.post("/experiments/{experiment_id}/batch_predict", response={200: BatchPredictionOut, 400: ErrorOut})
def batch_predict_experiment(request, experiment_id: int, payload: BatchPredictionIn):
    """
    è¤‡æ•°SMILESã«å¯¾ã—ã¦ãƒãƒƒãƒäºˆæ¸¬ã‚’å®Ÿè¡Œ
    """
    experiment = get_object_or_404(Experiment, id=experiment_id)
    
    if experiment.status != 'COMPLETED':
        return 400, {"detail": "Experiment not completed"}
    
    try:
        from core.services.features.rdkit_eng import RDKitFeatureExtractor
        from core.services.ml.tracking import MLTracker

        # ç‰¹å¾´é‡æŠ½å‡º
        extractor = RDKitFeatureExtractor()
        X = extractor.transform(payload.smiles_list)
        X = X.drop(columns=['SMILES'], errors='ignore')
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        tracker = MLTracker(experiment_name=experiment.name)
        model = tracker.load_latest_model()
        
        if model is None:
            return 400, {"detail": "Model not found"}
        
        # äºˆæ¸¬
        predictions = model.predict(X)
        
        results = [
            {"smiles": smi, "prediction": float(pred)}
            for smi, pred in zip(payload.smiles_list, predictions)
        ]
        
        return {"predictions": results}
        
    except Exception as e:
        logger.error(f"Batch prediction failed: {e}")
        return 400, {"detail": str(e)}


@api.get("/experiments/{experiment_id}/artifacts/{filename}")
def get_experiment_artifact(request, experiment_id: int, filename: str):
    """
    å®Ÿé¨“ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼ˆç”»åƒç­‰ï¼‰ã‚’å–å¾—
    """
    experiment = get_object_or_404(Experiment, id=experiment_id)
    
    try:
        # MLflowã‹ã‚‰æœ€æ–°ã®runã‚’å–å¾—
        current_exp = mlflow.get_experiment_by_name(experiment.name)
        if not current_exp:
            raise Http404("Experiment not found in MLflow")
        
        runs = mlflow.search_runs(
            experiment_ids=[current_exp.experiment_id],
            order_by=["start_time DESC"],
            max_results=1,
        )
        
        if runs.empty:
            raise Http404("No runs found")
        
        run_id = runs.iloc[0].run_id
        
        # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        local_path = mlflow.artifacts.download_artifacts(
            run_id=run_id,
            artifact_path=filename,
        )
        
        content_type = mimetypes.guess_type(filename)[0] or 'application/octet-stream'
        
        with open(local_path, "rb") as f:
            return HttpResponse(f.read(), content_type=content_type)
            
    except Http404:
        raise
    except Exception as e:
        logger.warning(f"Artifact not found: {filename} - {e}")
        raise Http404(f"Artifact not found: {filename}")


@api.post("/experiments/{experiment_id}/predict", response={200: PredictionOut, 400: ErrorOut})
def predict_experiment(request, experiment_id: int, payload: PredictionIn):
    """
    è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ
    """
    experiment = get_object_or_404(Experiment, id=experiment_id)
    
    if experiment.status != 'COMPLETED':
        return 400, {"detail": "Experiment not completed"}
    
    try:
        from core.services.features.rdkit_eng import RDKitFeatureExtractor
        from core.services.features.uma_eng import UMAFeatureExtractor
        from core.services.features.xtb_eng import XTBFeatureExtractor
        from core.services.ml.tracking import MLTracker
        from core.services.vis.shap_eng import SHAPEngine
        
        smiles_list = [payload.smiles]
        features_df_list = []
        
        # ç‰¹å¾´é‡æŠ½å‡º
        if 'rdkit' in experiment.config['features']:
            features_df_list.append(RDKitFeatureExtractor().transform(smiles_list))
        
        if 'xtb' in experiment.config['features']:
            features_df_list.append(XTBFeatureExtractor().transform(smiles_list))
        
        if 'uma' in experiment.config['features']:
            # UMAãƒ¢ãƒ‡ãƒ«ã‚’MLflowã‹ã‚‰ãƒ­ãƒ¼ãƒ‰
            uma_eng = _load_uma_model(experiment.name)
            if uma_eng:
                features_df_list.append(uma_eng.transform(smiles_list))
        
        if not features_df_list:
            return 400, {"detail": "Feature extraction failed"}
        
        # ç‰¹å¾´é‡çµåˆ
        X_pred = pd.concat(
            [f.drop(columns=['SMILES'], errors='ignore') for f in features_df_list],
            axis=1,
        )
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        tracker = MLTracker(experiment_name=experiment.name)
        model = tracker.load_latest_model()
        
        if model is None:
            return 400, {"detail": "Model not found"}
        
        # äºˆæ¸¬
        prediction = model.predict(X_pred)[0]
        
        # SHAPèª¬æ˜
        shap_image = _generate_shap_image(model, X_pred)
        
        return {
            "prediction": float(prediction),
            "shap_image": shap_image,
        }
        
    except Exception as e:
        logger.error(f"Prediction failed: {e}")
        return 400, {"detail": str(e)}


def _load_uma_model(experiment_name: str):
    """UMAãƒ¢ãƒ‡ãƒ«ã‚’MLflowã‹ã‚‰ãƒ­ãƒ¼ãƒ‰"""
    try:
        from core.services.features.uma_eng import UMAFeatureExtractor
        
        current_exp = mlflow.get_experiment_by_name(experiment_name)
        if not current_exp:
            return None
        
        runs = mlflow.search_runs(
            experiment_ids=[current_exp.experiment_id],
            order_by=["start_time DESC"],
            max_results=1,
        )
        
        if runs.empty:
            return None
        
        run_id = runs.iloc[0].run_id
        local_path = mlflow.artifacts.download_artifacts(
            run_id=run_id,
            artifact_path="uma_reducer.joblib",
        )
        
        uma_eng = UMAFeatureExtractor()
        uma_eng.load(local_path)
        return uma_eng
        
    except Exception as e:
        logger.warning(f"UMA model load failed: {e}")
        return None


def _generate_shap_image(model, X: pd.DataFrame) -> Optional[str]:
    """SHAP Force Plotã‚’ç”Ÿæˆ"""
    try:
        import shap

        from core.services.vis.shap_eng import SHAPEngine
        
        shap_eng = SHAPEngine(max_samples=1)
        shap_values, explainer = shap_eng.explain(model, X)
        
        # Force plotç”Ÿæˆ
        expected_value = explainer.expected_value
        if isinstance(expected_value, list):
            expected_value = expected_value[0]
        
        shap.force_plot(
            expected_value,
            shap_values[0] if len(shap_values.shape) > 1 else shap_values,
            X.iloc[0],
            matplotlib=True,
            show=False,
        )
        
        buf = io.BytesIO()
        plt.savefig(buf, format="png", bbox_inches='tight', dpi=100)
        plt.close()
        
        return base64.b64encode(buf.getvalue()).decode("utf-8")
        
    except Exception as e:
        logger.warning(f"SHAP image generation failed: {e}")
        return None
"""
LLM Assistant API Endpoints - Append to core/api.py
"""

# --- LLM Assistant Endpoints ---


class LLMFeatureSuggestionIn(Schema):
    """ç‰¹å¾´é‡é¸æŠã‚¢ãƒ‰ãƒã‚¤ã‚¹ãƒªã‚¯ã‚¨ã‚¹ãƒE""

    n_samples: int
    task_type: str = "regression"  # or "classification"
    target_property: str
    available_features: Optional[List[str]] = None


class LLMFeatureSuggestionOut(Schema):
    """ç‰¹å¾´é‡é¸æŠã‚¢ãƒ‰ãƒã‚¤ã‚¹ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""

    recommended_features: List[str]
    reasoning: str
    alternative_features: List[str]
    considerations: List[str]


class LLMAnalysisPlanIn(Schema):
    """è§£æãEãƒ©ãƒ³ææ¡ˆãƒªã‚¯ã‚¨ã‚¹ãƒE""

    problem_description: str
    n_samples: int
    task_type: str = "regression"
    target_property: str


class LLMAnalysisPlanOut(Schema):
    """è§£æãEãƒ©ãƒ³ææ¡ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹"""

    objective: str
    recommended_approach: str
    feature_engineering_steps: List[str]
    model_suggestions: List[str]
    validation_strategy: str
    potential_challenges: List[str]


class LLMInterpretResultsIn(Schema):
    """çµæœè§£é‡ˆãƒªã‚¯ã‚¨ã‚¹ãƒE""

    metrics: Dict[str, float]
    model_type: str = "unknown"


class LLMInterpretResultsOut(Schema):
    """çµæœè§£é‡ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹"""

    interpretation: str


class LLMAskIn(Schema):
    """è‡ªç”±å½¢å¼Q&Aãƒªã‚¯ã‚¨ã‚¹ãƒE""

    question: str
    context: Optional[str] = None


class LLMAskOut(Schema):
    """è‡ªç”±å½¢å¼Q&Aãƒ¬ã‚¹ãƒãƒ³ã‚¹"""

    question: str
    answer: str
    llm_available: bool


@api.post("/llm/suggest-features", response={200: LLMFeatureSuggestionOut, 400: ErrorOut})
def llm_suggest_features(request, payload: LLMFeatureSuggestionIn):
    """
    LLMã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒE ç‰¹å¾´é‡é¸æŠãEã‚¢ãƒ‰ãƒã‚¤ã‚¹

    ãƒEEã‚¿ã‚»ãƒEƒˆæƒE ±ã¨äºˆæ¸¬å¯¾è±¡ã®ç‰©æ€§ã‹ã‚‰ã€E©åˆEªç‰¹å¾´é‡ã‚’æ¨å¥¨ã—ã¾ã™ã€E
    """
    try:
        from core.services.llm import ChemMLAssistant

        assistant = ChemMLAssistant()

        dataset_info = {
            "n_samples": payload.n_samples,
            "task_type": payload.task_type,
            "target_property": payload.target_property,
        }

        suggestion = assistant.suggest_features(
            dataset_info=dataset_info,
            target_property=payload.target_property,
            available_features=payload.available_features,
        )

        return {
            "recommended_features": suggestion.recommended_features,
            "reasoning": suggestion.reasoning,
            "alternative_features": suggestion.alternative_features,
            "considerations": suggestion.considerations,
        }

    except Exception as e:
        logger.error(f"LLM feature suggestion failed: {e}")
        return 400, {"detail": str(e)}


@api.post("/llm/suggest-plan", response={200: LLMAnalysisPlanOut, 400: ErrorOut})
def llm_suggest_analysis_plan(request, payload: LLMAnalysisPlanIn):
    """
    LLMã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒE è§£æãEãƒ©ãƒ³ã®ææ¡E

    å•é¡Œè¨˜è¿°ã¨ãƒEEã‚¿ã‚»ãƒEƒˆæƒE ±ã‹ã‚‰ã€E©åˆEªè§£ææˆ¦ç•¥ã‚’ææ¡ˆã—ã¾ã™ã€E
    """
    try:
        from core.services.llm import ChemMLAssistant

        assistant = ChemMLAssistant()

        dataset_info = {
            "n_samples": payload.n_samples,
            "task_type": payload.task_type,
            "target_property": payload.target_property,
        }

        plan = assistant.suggest_analysis_plan(
            problem_description=payload.problem_description, dataset_info=dataset_info
        )

        return {
            "objective": plan.objective,
            "recommended_approach": plan.recommended_approach,
            "feature_engineering_steps": plan.feature_engineering_steps,
            "model_suggestions": plan.model_suggestions,
            "validation_strategy": plan.validation_strategy,
            "potential_challenges": plan.potential_challenges,
        }

    except Exception as e:
        logger.error(f"LLM analysis plan failed: {e}")
        return 400, {"detail": str(e)}


@api.post("/llm/interpret-results", response={200: LLMInterpretResultsOut, 400: ErrorOut})
def llm_interpret_results(request, payload: LLMInterpretResultsIn):
    """
    LLMã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒE ãƒ¢ãƒEƒ«çµæœã®è§£é‡E

    è©•ä¾¡æŒE¨™ã‹ã‚‰ã€çµæœã®è§£é‡ˆã¨æ”¹å–E¡ˆã‚’ææ¡ˆã—ã¾ã™ã€E
    """
    try:
        from core.services.llm import ChemMLAssistant

        assistant = ChemMLAssistant()

        interpretation = assistant.interpret_results(
            metrics=payload.metrics, model_type=payload.model_type
        )

        return {"interpretation": interpretation}

    except Exception as e:
        logger.error(f"LLM interpretation failed: {e}")
        return 400, {"detail": str(e)}


@api.post("/llm/ask", response={200: LLMAskOut, 400: ErrorOut})
def llm_ask(request, payload: LLMAskIn):
    """
    LLMã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒE è‡ªç”±å½¢å¼Q&A

    åŒ–å­¦æ©Ÿæ¢°å­¦ç¿’ã«é–¢ã™ã‚‹è³ªå•ã«å›ç­”ã—ã¾ã™ã€E
    """
    try:
        from core.services.llm import ChemMLAssistant

        assistant = ChemMLAssistant()

        answer = assistant.ask(question=payload.question, context=payload.context)

        return {
            "question": payload.question,
            "answer": answer,
            "llm_available": assistant.is_available,
        }

    except Exception as e:
        logger.error(f"LLM Q&A failed: {e}")
        return 400, {"detail": str(e)}
